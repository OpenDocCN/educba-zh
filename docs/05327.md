# PySpark AGG

> 原文:[https://www.educba.com/pyspark-agg/](https://www.educba.com/pyspark-agg/)

![PySpark AGG](../Images/84584cabf765e68b96844a46b8ca0b8d.png)

<noscript><img class="alignnone size-full wp-image-477823" src="../Images/84584cabf765e68b96844a46b8ca0b8d.png" alt="PySpark AGG" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG.jpg"/></noscript>

## PySpark AGG 简介

PYSPARK AGG 是一个聚合函数，是 PYSPARK 中提供的用于操作的功能。聚合操作对 PySpark 的数据帧进行操作，并生成相同的结果。它对一组行进行操作，然后为每组计算返回值。该函数处理计算出的某些列值，结果显示在 PySpark 操作中。

PySpark 中有一些聚合函数用于 Python PySpark 模型中的操作。其中一些包括计数、最大值、最小值和平均值，用于对数据框中的列进行操作。该函数对给定的一组值进行计算，并返回单个值。

<small>网页开发、编程语言、软件测试&其他</small>

在本文中，我们将尝试分析 PySpark 中用于数据聚合的各种方法。

【PySpark Agg 的语法

语法如下所示:

```
c.agg({'ID':'sum'}).show()
```

*   **c:** 新的数据帧 post 分组依据。
*   **agg:** 基于列值使用的聚合函数。
*   **sum:** 聚合值为 sum。

**输出:**

![PySpark AGG-1.1](../Images/0e8bf3d57622282d1a697bc49fe360c7.png)

<noscript><img class="alignnone size-full wp-image-477658" src="../Images/0e8bf3d57622282d1a697bc49fe360c7.png" alt="PySpark AGG-1.1" width="363" height="69" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.1.png 363w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.1-300x57.png 300w" sizes="(max-width: 363px) 100vw, 363px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.1.png"/></noscript>

### PySpark 中的 AGG 操作是如何工作的？

聚合是基于 PySpark 数据帧上的几个逻辑规则来聚合数据的功能。它对一组行进行操作，并基于每个组计算单个返回值。每次调用聚合函数时，它们都返回相同的值。我们在 PySpark 中定义了一组聚合函数，对一组数据进行操作，然后将结果返回到内存中。

我们有几个已定义的聚合函数，这些函数具有为几个函数定义的功能，一些聚合函数包括 avg、max、min、count、sum，它们用于各种数据级操作。

让我们通过一些代码示例来检查聚合函数的创建和工作。

### PySpark AGG 示例

让我们看一些 PYSPARK AGG 操作如何工作的例子。让我们从在 PySpark 中创建简单数据开始。

```
data1  = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tina','ID':2.48,'Add':'IND'},{'Name':'Jhon','ID':22.22, 'Add':'USA'},{'Name':'Joe','ID':5.33,'Add':'INA'}]
```

创建一个示例数据，字段为 Name、ID 和 ADD。

```
a = sc.parallelize(data1)
```

RDD 是使用 sc.parallelize 创建的

```
b = spark.createDataFrame(a)
b.show()
```

使用 Spark.createDataFrame 创建了数据框。

**输出:**

![PySpark AGG-1.2](../Images/285a454619aa722757a5914511d32518.png)

<noscript><img class="alignnone size-full wp-image-477660" src="../Images/285a454619aa722757a5914511d32518.png" alt="PySpark AGG-1.2" width="698" height="139" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.2.png 698w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.2-300x60.png 300w" sizes="(max-width: 698px) 100vw, 698px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.2.png"/></noscript>

让我们尝试聚合这个 PySpark 数据框架的数据。

首先，我们将使用 data.groupBy()和需要分组的列名对数据进行分组。

```
c = b.groupBy('Name')
```

这将根据 PySpark 数据框的名称对列进行分组。我们可以使用聚合函数。

```
c.count()
c.count().show()
```

**输出:**

![PySpark AGG-1.3](../Images/ba41e9548af47d4c4104a98b7b39c577.png)

<noscript><img class="alignnone size-full wp-image-477661" src="../Images/ba41e9548af47d4c4104a98b7b39c577.png" alt="PySpark AGG-1.3" width="315" height="117" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.3.png 315w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.3-300x111.png 300w" sizes="(max-width: 315px) 100vw, 315px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.3.png"/></noscript>

dataframe.agg 函数占用要使用的列名和聚合函数。让我们用例子来验证一下。SUM 函数根据列值对分组数据求和。

```
c.agg({'ID':'sum'}).show()
```

MAX 函数根据提供的列名检查函数的最大值。

```
c.agg({'ID':'max'}).show()
```

计数功能包括总分组数据的计数。

```
c.agg({'ID':'count'}).show()
```

**输出:**

![1.4](../Images/7c9d7de973bce93f5ae175a65b0f3641.png)

<noscript><img class="alignnone wp-image-477664 size-full" src="../Images/7c9d7de973bce93f5ae175a65b0f3641.png" alt="1.4" width="337" height="469" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.4.png 337w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.4-216x300.png 216w" sizes="(max-width: 337px) 100vw, 337px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.4.png"/></noscript>

第一个函数聚合数据并从 PySpark 数据帧中收集第一个元素。

```
c.agg({'ID':'first'}).show()
```

最后一个函数聚集数据并取出最后一个值。

```
c.agg({'ID':'last'}).show()
```

AVG 函数根据提供的列值对数据进行平均。

```
c.agg({'ID':'avg'}).show()
```

**输出:**

![1.5](../Images/8188e744708cd4c50a5027179c9809c2.png)

<noscript><img class="alignnone wp-image-477665 size-full" src="../Images/8188e744708cd4c50a5027179c9809c2.png" alt="1.5" width="323" height="474" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.5.png 323w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.5-204x300.png 204w" sizes="(max-width: 323px) 100vw, 323px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.5.png"/></noscript>

MEAN 函数计算 PySpark 中列的平均值。这是一个集合函数。

```
c.agg({'ID':'mean'}).show()
```

STDDEV 函数计算给定列的标准偏差。

```
c.agg({'ID':'stddev'}).show()
```

collect_list 函数收集数据框的列作为列表元素。

```
c.agg({'ID':'collect_list'}).show()
```

collect_set 函数将数据框的数据收集到集合中，并显示结果。

```
c.agg({'ID':'collect_set'}).show()
```

**输出:**

![1.6](../Images/afaa06990b5b7b1e874c3283e9757311.png)

<noscript><img class="alignnone wp-image-477667 size-full" src="../Images/afaa06990b5b7b1e874c3283e9757311.png" alt="1.6" width="322" height="658" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.6.png 322w, https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.6-147x300.png 147w" sizes="(max-width: 322px) 100vw, 322px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/05/PySpark-AGG-1.6.png"/></noscript>

**注:**

1.  PySpark AGG 是一个函数，用于使用多个列值聚合 PySpark 中的数据。
2.  PySpark AGG 函数在聚合后返回单个值。
3.  PySpark 中的列分组后使用 PySpark AGG 函数。
4.  PySpark AGG 函数为传递给它们的列列表定义了一组操作。
5.  PySpark AGG 涉及数据洗牌和移动。

### 结论

从上面的文章中，我们看到了 AGG 在 PySpark 的工作。通过各种例子和分类，我们试图理解 PySpark AGG 中的 AGG 操作是如何发生的，以及在编程级别使用了什么。我们还看到了 PySpark 数据框架中 AGG 的内部工作方式和优势，以及它在各种编程目的中的使用。此外，语法和例子帮助我们更准确地理解函数。

### 推荐文章

这是 PySpark AGG 的指南。在这里，我们还将讨论 PySpark 中 AGG 操作的介绍和工作原理，以及不同的示例和代码实现。您也可以看看以下文章，了解更多信息–

1.  [PySpark 回合](https://www.educba.com/pyspark-round/)
2.  [pypark 交换机列](https://www.educba.com/pyspark-withcolumn/)
3.  [py 帕克集团](https://www.educba.com/pyspark-groupby/)
4.  [PySpark foreach](https://www.educba.com/pyspark-foreach/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>