# 派斯帕克集团

> 原文:[https://www.educba.com/pyspark-groupby/](https://www.educba.com/pyspark-groupby/)

![PySPark Groupby](../Images/70116b74cec4852eb9c23accb7b9a504.png)

<noscript><img class="alignnone size-full wp-image-457824" src="../Images/70116b74cec4852eb9c23accb7b9a504.png" alt="PySPark Groupby" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySPark-Groupby.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySPark-Groupby-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySPark-Groupby-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySPark-Groupby.jpg"/></noscript>

## PySPark Groupby 简介

PYSPARK GROUPBY 是 PYSPARK 中的一个函数，它允许根据 SPARK 应用程序中的一些列值对行进行分组。group By 函数用于根据某些条件对数据进行分组，最终的聚合数据显示为结果。简而言之，如果我们试图理解 group by 在 PySpark 中的确切作用，只需对 Spark 数据帧中的行进行分组，这些数据帧中的一些值可以进一步聚合到某个给定的结果集中。

相同的数据按组排列，并根据分区和条件相应地打乱数据。PySpark GroupBy 还支持多列数据高级聚合。在数据帧上执行 Group By 后，返回类型是一个关系分组数据集对象，它包含聚合函数，我们可以从该函数中聚合数据。

<small>网页开发、编程语言、软件测试&其他</small>

【PySPark Groupby 的语法

PYSPARK GROUPBY 函数的语法是:-

`df.groupBy(‘columnName’).max().show()
df :- The PySpark DataFrame
ColumnName :- The ColumnName for which the GroupBy Operations needs to be done.
Max() – A Sample Aggregate Function
a.groupBy(“Name”).max().show()`

截图:-

![PySpark groupby output 1](../Images/a4db4a2ee4c0ce52cefd083c2ef151b6.png)

<noscript><img class="alignnone size-full wp-image-457669" src="../Images/a4db4a2ee4c0ce52cefd083c2ef151b6.png" alt="PySpark groupby output 1" width="364" height="73" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-1.png 364w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-1-300x60.png 300w" sizes="(max-width: 364px) 100vw, 364px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-1.png"/></noscript>

### PySPark Groupby 的工作

让我们看看 GROUPBY 函数在 PySpark 中是如何工作的

GROUPBY 函数用于根据对 PySpark 应用程序中的 RDD /数据帧进行操作的相同键值将数据分组在一起。

具有相同密钥的数据被混洗在一起，并被带到可以分组在一起的位置。洗牌发生在整个网络上，这使得操作有点昂贵。

具有相同键的组合在一起，并根据条件返回值。

GroupBy 语句通常与 count、max、min、avg 等聚合函数一起使用，然后对结果集进行分组。

Group By 可用于将多个列和多个列名组合在一起。Group By 为组合在一起的每个组合返回一行，聚合函数用于计算分组数据的值。

### 例子

让我们看一些 PYSPARK GROUPBY 函数如何工作的例子

让我们首先创建一个简单的数据框，我们希望使用过滤操作。

数据帧的创建:-

`a= spark.createDataFrame(["SAM","JOHN","AND","ROBIN","ANAND"], "string").toDF("Name")`

让我们从一个简单的 groupBy 代码开始，它在数据框中过滤名称。

`a.groupby("Name").avg().show()`

这将按名称对元素进行分组。具有相同关键字元素被分组在一起，并显示结果。

后聚合功能可以显示数据。

截图:-

![PySpark groupby output 2](../Images/8f35f9fd3accd817bb13ff978f3f1759.png)

<noscript><img class="alignnone size-full wp-image-457670" src="../Images/8f35f9fd3accd817bb13ff978f3f1759.png" alt="PySpark groupby output 2" width="624" height="158" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-2.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-2-300x76.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-2-620x158.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-2.png"/></noscript>

让我们通过创建一个包含多个列的数据框并在其中使用聚合函数来更准确地理解这一点。

`data1  = [{'Name':'Jhon','ID':2,'Add':'USA'},{'Name':'Joe','ID':3,'Add':'USA'},{'Name':'Tina','ID':2,'Add':'IND'}]`

创建一个示例数据，字段为 Name、ID 和 ADD。

`a = sc.parallelize(data1)`

RDD 是使用 sc.parallelize 创建的

`b = spark.createDataFrame(a)`

使用 Spark.createDataFrame 创建了 DataFrame。

`b.groupBy("Add").max().show()`

使用聚合函数 max，其在对数据进行分组后取最大值。

最大值将显示为输出。

截图:-

![PySpark groupby output 3](../Images/049709b13eb22adab3955fe073cd0410.png)

<noscript><img class="alignnone size-full wp-image-457671" src="../Images/049709b13eb22adab3955fe073cd0410.png" alt="PySpark groupby output 3" width="624" height="183" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-3.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-3-300x88.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-3-620x183.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-3.png"/></noscript>

假设我们想对组合在一起的函数求和。

为此，我们将使用聚合函数 sum()对 id 求和。

`b.groupBy("Add").sum().show()`

这将对数据进行分组并求和。

输出:-

截图:-

![PySpark groupby output 4](../Images/53334dc5160e045564616400da5343a7.png)

<noscript><img class="alignnone size-full wp-image-457672" src="../Images/53334dc5160e045564616400da5343a7.png" alt="PySpark groupby output 4" width="283" height="126" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-4.png"/></noscript>

agg 函数也可以使用相同的方法，在对数据帧进行分组后聚合数据。

`b.groupBy("Add").agg({'id':'max'}).show()`

输出:-

输出将具有相同的结果，给出最大的 ID。

这同样适用于求和运算。

`b.groupBy("Add").agg({'id':'sum'}).show()`

这与获得的结果相同。

截图:-

![output 5](../Images/5776bd69d0868f69c70d6b7a33ba6c42.png)

<noscript><img class="alignnone wp-image-457673 size-full" src="../Images/5776bd69d0868f69c70d6b7a33ba6c42.png" alt="output 5" width="362" height="243" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-5.png 362w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-5-300x201.png 300w" sizes="(max-width: 362px) 100vw, 362px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-5.png"/></noscript>

让我们使用 groupBy 检查更多的聚合函数。

获取最少的数据。

`b.groupBy("Add").min("id").show()`

输出:-

得到平均值。

`b.groupBy("Add").avg("id").show()`

得到数据的平均值。

`b.groupBy("Add").mean("id").show()`

截图:-

![output 6](../Images/06620a178afadbd644173d8876983ab3.png)

<noscript><img class="alignnone wp-image-457674 size-full" src="../Images/06620a178afadbd644173d8876983ab3.png" alt="output 6" width="420" height="555" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-6.png 420w, https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-6-227x300.png 227w" sizes="(max-width: 420px) 100vw, 420px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/02/PySpark-groupby-output-6.png"/></noscript>

这是 PySpark 中 GroupBy 函数的一些例子。

### 结论

从上面的文章中我们看到了 PySpark 中 groupBy 操作的使用。从各种例子和分类中，我们试图理解 GROUPBY 方法在 PySpark 中是如何工作的，以及在编程级别使用了什么。

我们还看到了 Spark 数据框架中 GroupBy 的内部工作和优点，以及它在各种编程目的中的使用。语法和例子也帮助我们更精确地理解这个函数。

### 推荐文章

这是 PySPark Groupby 的指南。在这里，我们将讨论在 PySpark 中使用 groupBy 操作，以及各种示例和分类。您也可以看看以下文章，了解更多信息–

1.  [PySpark SQL](https://www.educba.com/pyspark-sql/)
2.  [PySpark 加入](https://www.educba.com/pyspark-join/)
3.  [火花簇](https://www.educba.com/spark-cluster/)
4.  [火花提交](https://www.educba.com/spark-submit/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>