# PySpark 平面图

> 原文:[https://www.educba.com/pyspark-flatmap/](https://www.educba.com/pyspark-flatmap/)

![PySpark FlatMap](../Images/afc442b75062867c1ff80ccd7b7759d9.png)

<noscript><img class="alignnone size-full wp-image-493034" src="../Images/afc442b75062867c1ff80ccd7b7759d9.png" alt="PySpark FlatMap" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap.jpg"/></noscript>

## PySpark 平面图简介

PySpark 平面图是 PySpark RDD/数据框模型中的变换操作，用于 py spark 数据模型中的每个元素。它适用于 RDD 的每一个元素，回报是一个新的 RDD。这个转换函数从 RDD 中提取所有元素，并将定制的业务逻辑应用于元素。这个逻辑可以适用于 RDD 的每一个元素。它通过对 RDD 上的所有元素应用一个函数来拼合 RDD，并返回一个新的 RDD 作为结果。返回类型可以是元素列表，根据应用于元素的业务转换，返回类型可以是 0 或 1 以上。它是一个一对多的转换模型。

### PySpark 平面图的语法

PySpark 平面图函数的语法是:

<small>网页开发、编程语言、软件测试&其他</small>

`d1 = ["This is an sample application to see the FlatMap operation in PySpark"] rdd1 = spark.sparkContext.parallelize(d1)
rdd2 = rdd1.flatMap(lambda x: x.split(" "))
rdd2.foreach(print)`

它将输入数据框作为输入函数，结果存储在新的列值中。

**输出:**

![PySpark FlatMap 1](../Images/d023f99dece3f937ef28b7e264cb86c1.png)

<noscript><img class="alignnone wp-image-492857 size-full" src="../Images/d023f99dece3f937ef28b7e264cb86c1.png" alt="PySpark FlatMap 1" width="565" height="98" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-1.jpg 565w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-1-300x52.jpg 300w" sizes="(max-width: 565px) 100vw, 565px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-1.jpg"/></noscript>

### PySpark 中的 FlatMap 工作

*   平面图是一种转换操作，用于将业务自定义逻辑应用于 PySpark RDD/数据框中的每个元素。这个 FlatMap 函数通过遍历 PySpark 中的每个元素来获取一个元素作为输入，并将用户定义的逻辑应用于其中。这将返回一个新的 RDD，其长度可以不同于以前的长度。
*   这是 PySpark 数据模型中的一对多转换。对 RDD 中的每个元素应用一个函数，输出是不同大小的新的展平 RDD。每个元素的变换可以是 0 或更多。这也可以应用于 PySpark 中的数据帧，该模型与 RDD 模型相同，并且输出被返回。我们可以定义自己的自定义逻辑以及一个内置函数，也可以使用平面图功能，并可以获得所需的结果。

### PySpark 平面图示例

下面是提到的例子:

#### 示例#1

首先，从 PySpark 数据创建数据和简单的 RDD。

**代码:**

`d1 = ["This is an sample application to see the FlatMap operation in PySpark"]`

spark.sparkContext.parallelize 函数将用于根据该数据创建 RDD。

**代码:**

`rdd1 = spark.sparkContext.parallelize(d1)`

RDD 创建后，我们可以使用平面图操作来嵌入一个自定义的简单的用户定义函数，该函数适用于 RDD 中的每个元素。

**代码:**

`rdd2 = rdd1.flatMap(lambda x: x.split(" "))`

此函数根据空间值分割数据，然后将结果收集到新的 RDD 中。

**代码:**

`rdd2.foreach(print)`

**输出:**

![PySpark FlatMap 2](../Images/cc3581491cb085d785b4d5aeade2ed7b.png)

<noscript><img class="alignnone wp-image-492865 size-full" src="../Images/cc3581491cb085d785b4d5aeade2ed7b.png" alt="PySpark FlatMap 2" width="801" height="355" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-2.jpg 801w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-2-300x133.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-2-768x340.jpg 768w" sizes="(max-width: 801px) 100vw, 801px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-2.jpg"/></noscript>

#### 实施例 2

让我们再看一个例子，我们将使用 Python 定义的函数来收集范围，并在新的 RDD 中检查结果。

**代码:**

`sc.parallelize([3,4,5]).flatMap(lambda x: range(1,x)).collect()`

这导致输出采用每个元素。

该函数使用 range 函数，并使用 FlatMap 操作收集数据。这将逐个获取每个元素，并获取 Python 的范围。

**代码:**

`sc.parallelize([3,6,5]).flatMap(lambda x: range(1,x)).collect()`

**输出:**

![data frame needs to be converted into RDD first](../Images/a4ec34e12176582cde4c003713001149.png)

<noscript><img class="alignnone wp-image-492868 size-full" src="../Images/a4ec34e12176582cde4c003713001149.png" alt="data frame needs to be converted into RDD first" width="732" height="145" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-4.jpg 732w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-4-300x59.jpg 300w" sizes="(max-width: 732px) 100vw, 732px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-4.jpg"/></noscript>

同样的平面图操作也可用于 PySpark 数据框操作。首先需要将此数据框转换为 RDD，然后才能对其应用平面地图操作。

**代码:**

`data1 = [("Jhon Jus","Jack Rose","Mack Tim")] data_frame = spark.createDataFrame(data=data1, schema = ['name'])
w = data_frame.rdd.flatMap(lambda x: x.split(" "))`

可以在数据帧上写入样本平面图，然后收集数据。

**输出:**

![can be collected there after](../Images/da1fc70f4146a8dd1cb26fe32203eeff.png)

<noscript><img class="alignnone wp-image-492873 size-full" src="../Images/da1fc70f4146a8dd1cb26fe32203eeff.png" alt="can be collected there after" width="741" height="109" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-5.jpg 741w, https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-5-300x44.jpg 300w" sizes="(max-width: 741px) 100vw, 741px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/07/PySpark-FlatMap-5.jpg"/></noscript>

**Note:** PySpark FlatMap is a transformation function in PySpark. It applies to every element in a PySpark data model. It returns a new RDD that can be a list of elements 0 or more. It is a One Many Transformation approaches in the PySpark model.

### 结论

从上面的文章中，我们看到了 PySpark 中 FlatMap 的工作原理。从各种例子和分类中，我们试图理解这个 FlatMap 函数在 PySpark 中是如何使用的，以及在编程级别使用了什么。所使用的各种方法显示了它如何简化数据分析的模式以及同样的成本效益模型。我们还看到了 PySpark 数据框架中的 FlatMap 的内部工作和优势，以及它在各种编程目的中的使用。此外，语法和例子帮助我们更准确地理解函数。

### 推荐文章

这是 PySpark 平面图的指南。在这里，我们讨论 PySpark 中的 FlatMap 的介绍、工作原理，并举例说明以便更好地理解。您也可以看看以下文章，了解更多信息–

1.  [PySpark 回合](https://www.educba.com/pyspark-round/)
2.  [PySpark 列到列表](https://www.educba.com/pyspark-column-to-list/)
3.  [PySpark 选择列](https://www.educba.com/pyspark-select-columns/)
4.  [PySpark 加入](https://www.educba.com/pyspark-join/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>