# PySpark 选择列

> 原文：<https://www.educba.com/pyspark-select-columns/>

![PySpark Select Columns](img/51664bb0f8b0566986714a4df981a63b.png)



## PySpark 选择色谱柱简介

PySpark Select Columns 是 PySpark 中使用的一个函数，用于选择 PySpark 数据框中的列。它可以是数据帧的整列、单列以及多列。变换函数每次都返回一个新的数据帧，其中包含条件。我们还可以使用 select 函数从列表中选择所有的列。

选择列是 PySpark 数据框中非常重要的功能，它赋予我们在 PYSPARK 中选择所需列的特权，使数据更加明确和可用。使用 select 列，我们可以选择我们需要的列，并将 PySpark 数据框中不需要的其余列保留下来。

<small>网页开发、编程语言、软件测试&其他</small>

**语法:**

PySpark 选择列函数的语法是:

`b.select("*").show()`

b:用于操作的数据帧。

*   select():用于选择列的选择操作。
*   Show():用于显示数据框的操作。

**截图:**

![PySpark 1](img/43e01b6918d8a81b5f2d2934c5e370a1.png)



### PySpark 中选择列的工作

让我们看看 PySpark 中的 SELECT COLUMN 函数是如何工作的:

SELECT 函数从 PySpark 数据框的数据库中选择列。它是一个变换函数，占用现有的数据帧并选择进一步需要的数据帧。将选定的数据帧放入新的数据帧中。该方法查找选择列时给出的参数，创建新的数据框，并返回给用户进行操作。

生成一个查询计划，用于检索在 select 语句中作为参数给出的特定列。该计划以一种优化的方式执行，返回结果集并给出其中的值。关键字*指定返回 PYSPARK 数据框中的所有列。

数据框模型中的 select 语句类似于 SQL 模型，在 SQL 模型中，我们使用 select 语句从数据框中选择一组记录来写下查询。
我们可以使用 select column 从 PySpark 数据框中选择单个列、多个列、由 Index 引导的列或嵌套列。让我们用一些编码例子来检查这些。

### 例子

让我们看一些 PySpark 选择列函数如何工作的例子:

让我们从在 PySpark 中创建简单数据开始。

`data1 = [{'Name':'Jhon','ID':2,'Add':'USA'},{'Name':'Joe','ID':3,'Add':'USA'},{'Name':'Tina','ID':2,'Add':'IND'},{'Name':'Jhon','ID':2, 'Add':'USA'},{'Name':'Joe','ID':5,'Add':'INA'}]`

创建一个示例数据，字段为 Name、ID 和 ADD。

`a = sc.parallelize(data1)`

RDD 是使用 sc.parallelize 创建的

`b = spark.createDataFrame(a)
b.show()`

使用 Spark.createDataFrame 创建了数据框。

**截图:**

![PySpark Select Columns](img/f9870229f670dd1c1a7bedd27c8acd0a.png)



检索数据帧的所有列。

**代码:**

`b.select("*").show()`

这将选择 PySpark 中数据框的所有列。

使用 PySpark 数据框中的选择选项选择特定列。

`b.select("Add").show()`

**输出:**

**截图:**

![Output 1](img/a1128df27b00bd575ebdb076c5b233f0.png)



其他列的代码:

`b.select("ID").show()`

这将从数据框中选择 ID 列。

同样可以通过混叠数据帧来完成。使用 DataFrame.ColumnName。

`b.select(b.ID).show()`

输出将与所选的相同。

**截图:**

![Output 2](img/adf2e796f684155bbfb21773f0de4a90.png)



我们还可以在数据框中循环变量，并用它选择 PySpark 数据框。

`b.select([col for col in b.columns]).show()`

同样的方法将遍历数据框中的所有列，并从中选择值。

我们也可以根据索引选择元素。索引方法可以从 select 语句中完成。

**代码:**

`b.select(b.columns[0:3]).show()`

这将从 0 到 3 中选择索引列并显示结果。

**输出:**

**截图:**

![Output 3](img/2eb8f638c5aff9870272b93b70504bb2.png)



这是 PySpark 中选择列函数的一些例子。

**注:**

*   PySpark select 是一个转换操作。
*   它选择分析数据所需的数据框架。
*   结果存储在新的数据框中。
*   我们可以从 PySpark 数据框中选择单个、多个、所有列。
*   所选数据可进一步用于 PySpark 操作的数据建模。
*   我们还可以使用 col 操作来选择数据，该操作为 PySpark 数据帧选择所需的列。

### 结论

从上面的文章中，我们看到了选择列操作在 PySpark 中的使用。从各种例子和分类中，我们试图理解在 PySpark 中 SELECT COLUMN 方法是如何工作的，以及在编程级别使用了什么。

我们还看到了 PySpark 数据框中 SELECT 列的内部工作和优点，以及它在各种编程目的中的用法。此外，语法和例子帮助我们更准确地理解函数。

### 推荐文章

这是 PySpark 选择柱的指南。这里我们讨论定义、语法，以及 SELECT COLUMN 函数在 PySpark 中如何工作，并给出例子。您也可以看看以下文章，了解更多信息–

1.  [PySpark substring](https://www.educba.com/pyspark-substring/)
2.  [PySpark 滤波器](https://www.educba.com/pyspark-filter/)
3.  [PySpark 版本](https://www.educba.com/pyspark-version/)
4.  [PySpark 加入](https://www.educba.com/pyspark-join/)





