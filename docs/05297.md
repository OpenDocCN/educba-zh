# 火花再分配

> 原文:[https://www.educba.com/spark-repartition/](https://www.educba.com/spark-repartition/)

![Spark Repartition](../Images/e8df65958165bee52006796f206e018b.png)

<noscript><img class="alignnone size-full wp-image-376283" src="../Images/e8df65958165bee52006796f206e018b.png" alt="Spark Repartition" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition.jpg"/></noscript>

## 星火再分配概论

repartition()方法用于增加或减少 spark 中 RDD 或数据帧的分区数量。该方法在所有节点上执行数据的完全混洗。它创建大小大致相等的分区。这是一项成本高昂的操作，因为它涉及整个网络上的数据移动。分区在并行度方面起着重要的作用。每个阶段中运行的并行任务的数量等于分区的数量。因此，我们可以使用 repartition()方法来控制并行性。它还在决定输出中生成的文件数量方面发挥作用。

**语法:**

<small>Hadoop、数据科学、统计学&其他</small>

`obj.repartition(numPartitions)`

这里，obj 是一个 RDD 或数据帧，numPartitions 是一个表示我们想要创建的分区数量的数字。

### 怎么用星火再分配？

为了使用该方法，必须遵循以下步骤:

1.  我们需要创建一个可以调用该方法的 RDD 或数据帧。我们可以通过以下方式创建 RDD/数据帧:a)从 hdfs 等外部源或 Cassandra 等数据库加载数据 b)调用 spark 上下文对象上的 parallelize()方法，并将集合作为参数传递(然后，如果需要，调用 toDf()数据帧)
2.  接下来是决定一个合适的数值。我们不能选择很大或很小的数值。这是因为如果我们选择一个非常大的值，那么将会生成大量的文件，hdfs 系统将很难维护元数据。另一方面，如果我们选择一个很小的值，那么每个分区中的数据将会很大，需要很长时间来处理。

### 火花再分配的例子

以下是火花再分配的例子:

#### 示例 1–在 rdd 上

数据集 us-counties.csv 以累积的方式表示美国县和州级电晕放电案例的数量。这个数据集是从 https://www.kaggle.com/获得的，最新的数据是 4 月 10 日在 T2 获得的。让我们找出美国各州截至 4 月 10 日<sup>的电晕案例数量。</sup>

**代码:**

`sc.setLogLevel("ERROR")
valmyRDD = sc.textFile("https://cdn.educba.com/home/hadoop/work/arindam/us-counties.csv")
myRDD.take(5).foreach(println) //Printing to show how the data looks like
println("Number of partitions in myRDD: "+myRDD.getNumPartitions) //Printing no of partitions
val head = myRDD.first()
val myRDD1 = myRDD.filter(x=>x!=head &&x.split(",")(0)=="2020-04-10") //Filtering out header and taking latest data available
val myRDD2 = myRDD1.repartition(10) // repartitioning to 10 partitions
println("Number of partitions in myRDD: "+myRDD2.getNumPartitions) //Printing partitions after repartition
val myRDD3 = myRDD2.map(x=>(x.split(",")(2),x.split(",")(4).toLong)) //Creating pairWise RDD with State and no of cases
valrslt = myRDD3.reduceByKey((x,y)=>x+y).collect().sortBy(x=>x._2)(Ordering[Long].reverse) //Summing up all the values of cases
rslt.foreach(println)`

**输出:**

![Spark Repartition-1.1](../Images/c3ab4304c6f4e66ac80de0f114e9686d.png)

<noscript><img class="alignnone size-full wp-image-376101" src="../Images/c3ab4304c6f4e66ac80de0f114e9686d.png" alt="Spark Repartition-1.1" width="2864" height="1494" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1.png 2864w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1-300x156.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1-1024x534.png 1024w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1-768x401.png 768w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1-1536x801.png 1536w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1-2048x1068.png 2048w" sizes="(max-width: 2864px) 100vw, 2864px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.1.png"/></noscript>

我们将根据案例数量以降序方式对输出进行排序，以适应输出中一些受影响最大的州。

**火花 UI:**

![Spark Repartition-1.2](../Images/9e6c2f0da3c64c92836ca6cf6c9842d7.png)

<noscript><img class="alignnone size-full wp-image-376102" src="../Images/9e6c2f0da3c64c92836ca6cf6c9842d7.png" alt="Spark Repartition-1.2" width="2133" height="638" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2.png 2133w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2-300x90.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2-1024x306.png 1024w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2-768x230.png 768w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2-1536x459.png 1536w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2-2048x613.png 2048w" sizes="(max-width: 2133px) 100vw, 2133px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.2.png"/></noscript>

由于我们创建了 10 个分区，最后两个阶段产生了 10 个任务。

#### 示例 2–在数据帧上

让我们考虑与示例 1 相同的问题，但这次我们将使用 dataframes 和 spark-sql 来解决。

**代码:**

`import org.apache.spark.sql.types.{LongType, StringType, StructField, StructType}
valinputSchema = StructType(Array(
StructField("date",StringType,true),
StructField("county",StringType,true),
StructField("state",StringType,true),
StructField("fips",LongType,true),
StructField("cases",LongType,true),
StructField("deaths",LongType,true)
))
valinpPath="https://cdn.educba.com/home/hadoop/work/arindam/us-counties.csv"
valdf = spark.read.option("header",true).schema(inputSchema).csv(inpPath)
df.show(5,false) //printing 5 rows
println("No of partitions in df: "+ df.rdd.getNumPartitions)
valnewDf = df.repartition(10)
println("No of partitions in newDf: "+ newDf.rdd.getNumPartitions)
newDf.createOrReplaceTempView("tempTable")
spark.sql("select state,SUM(cases) as cases from tempTable where date='2020-04-10' group by state order by cases desc").show(10,false)`

这里我们首先创建了一个模式。然后，在读取 csv 文件时，我们使用已定义的模式来创建数据帧。然后，我们调用 repartition 方法，将分区更改为 10。之后，我们将 dataframenewDf 注册为一个临时表。最后，我们编写了一个 spark sql 查询来获得所需的结果。请注意，我们没有任何方法可以直接从数据帧中获得分区的数量。我们必须将数据帧转换为 RDD，然后调用 getNumPartitions 方法来获得可用分区的数量。

**输出:**

![Spark Repartition-1.3](../Images/450129896ecf6a1013e8cc935a516e30.png)

<noscript><img class="alignnone size-full wp-image-376103" src="../Images/450129896ecf6a1013e8cc935a516e30.png" alt="Spark Repartition-1.3" width="2036" height="1306" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.3.png 2036w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.3-300x192.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.3-1024x657.png 1024w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.3-768x493.png 768w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.3-1536x985.png 1536w" sizes="(max-width: 2036px) 100vw, 2036px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Repartition-1.3.png"/></noscript>

我们在这里只打印前十个州，结果与上一个例子中计算的结果相匹配。

### 推荐文章

这是一个星火再分配的指南。在这里，我们还讨论了介绍和如何使用 spark 重新分区，以及不同的例子和它的代码实现。您也可以看看以下文章，了解更多信息–

1.  [火花版本](https://www.educba.com/spark-versions/)
2.  [纵向数据分析](https://www.educba.com/longitudinal-data-analysis/)
3.  [纵向数据分析](https://www.educba.com/longitudinal-data-analysis/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>