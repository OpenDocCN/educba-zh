# 火花再分配

> 原文：<https://www.educba.com/spark-repartition/>

![Spark Repartition](img/e8df65958165bee52006796f206e018b.png)



## 星火再分配概论

repartition()方法用于增加或减少 spark 中 RDD 或数据帧的分区数量。该方法在所有节点上执行数据的完全混洗。它创建大小大致相等的分区。这是一项成本高昂的操作，因为它涉及整个网络上的数据移动。分区在并行度方面起着重要的作用。每个阶段中运行的并行任务的数量等于分区的数量。因此，我们可以使用 repartition()方法来控制并行性。它还在决定输出中生成的文件数量方面发挥作用。

**语法:**

<small>Hadoop、数据科学、统计学&其他</small>

`obj.repartition(numPartitions)`

这里，obj 是一个 RDD 或数据帧，numPartitions 是一个表示我们想要创建的分区数量的数字。

### 怎么用星火再分配？

为了使用该方法，必须遵循以下步骤:

1.  我们需要创建一个可以调用该方法的 RDD 或数据帧。我们可以通过以下方式创建 RDD/数据帧:a)从 hdfs 等外部源或 Cassandra 等数据库加载数据 b)调用 spark 上下文对象上的 parallelize()方法，并将集合作为参数传递(然后，如果需要，调用 toDf()数据帧)
2.  接下来是决定一个合适的数值。我们不能选择很大或很小的数值。这是因为如果我们选择一个非常大的值，那么将会生成大量的文件，hdfs 系统将很难维护元数据。另一方面，如果我们选择一个很小的值，那么每个分区中的数据将会很大，需要很长时间来处理。

### 火花再分配的例子

以下是火花再分配的例子:

#### 示例 1–在 rdd 上

数据集 us-counties.csv 以累积的方式表示美国县和州级电晕放电案例的数量。这个数据集是从 https://www.kaggle.com/获得的，最新的数据是 4 月 10 日在 T2 获得的。让我们找出美国各州截至 4 月 10 日<sup>的电晕案例数量。</sup>

**代码:**

`sc.setLogLevel("ERROR")
valmyRDD = sc.textFile("https://cdn.educba.com/home/hadoop/work/arindam/us-counties.csv")
myRDD.take(5).foreach(println) //Printing to show how the data looks like
println("Number of partitions in myRDD: "+myRDD.getNumPartitions) //Printing no of partitions
val head = myRDD.first()
val myRDD1 = myRDD.filter(x=>x!=head &&x.split(",")(0)=="2020-04-10") //Filtering out header and taking latest data available
val myRDD2 = myRDD1.repartition(10) // repartitioning to 10 partitions
println("Number of partitions in myRDD: "+myRDD2.getNumPartitions) //Printing partitions after repartition
val myRDD3 = myRDD2.map(x=>(x.split(",")(2),x.split(",")(4).toLong)) //Creating pairWise RDD with State and no of cases
valrslt = myRDD3.reduceByKey((x,y)=>x+y).collect().sortBy(x=>x._2)(Ordering[Long].reverse) //Summing up all the values of cases
rslt.foreach(println)`

**输出:**

![Spark Repartition-1.1](img/c3ab4304c6f4e66ac80de0f114e9686d.png)



我们将根据案例数量以降序方式对输出进行排序，以适应输出中一些受影响最大的州。

**火花 UI:**

![Spark Repartition-1.2](img/9e6c2f0da3c64c92836ca6cf6c9842d7.png)



由于我们创建了 10 个分区，最后两个阶段产生了 10 个任务。

#### 示例 2–在数据帧上

让我们考虑与示例 1 相同的问题，但这次我们将使用 dataframes 和 spark-sql 来解决。

**代码:**

`import org.apache.spark.sql.types.{LongType, StringType, StructField, StructType}
valinputSchema = StructType(Array(
StructField("date",StringType,true),
StructField("county",StringType,true),
StructField("state",StringType,true),
StructField("fips",LongType,true),
StructField("cases",LongType,true),
StructField("deaths",LongType,true)
))
valinpPath="https://cdn.educba.com/home/hadoop/work/arindam/us-counties.csv"
valdf = spark.read.option("header",true).schema(inputSchema).csv(inpPath)
df.show(5,false) //printing 5 rows
println("No of partitions in df: "+ df.rdd.getNumPartitions)
valnewDf = df.repartition(10)
println("No of partitions in newDf: "+ newDf.rdd.getNumPartitions)
newDf.createOrReplaceTempView("tempTable")
spark.sql("select state,SUM(cases) as cases from tempTable where date='2020-04-10' group by state order by cases desc").show(10,false)`

这里我们首先创建了一个模式。然后，在读取 csv 文件时，我们使用已定义的模式来创建数据帧。然后，我们调用 repartition 方法，将分区更改为 10。之后，我们将 dataframenewDf 注册为一个临时表。最后，我们编写了一个 spark sql 查询来获得所需的结果。请注意，我们没有任何方法可以直接从数据帧中获得分区的数量。我们必须将数据帧转换为 RDD，然后调用 getNumPartitions 方法来获得可用分区的数量。

**输出:**

![Spark Repartition-1.3](img/450129896ecf6a1013e8cc935a516e30.png)



我们在这里只打印前十个州，结果与上一个例子中计算的结果相匹配。

### 推荐文章

这是一个星火再分配的指南。在这里，我们还讨论了介绍和如何使用 spark 重新分区，以及不同的例子和它的代码实现。您也可以看看以下文章，了解更多信息–

1.  [火花版本](https://www.educba.com/spark-versions/)
2.  [纵向数据分析](https://www.educba.com/longitudinal-data-analysis/)
3.  [纵向数据分析](https://www.educba.com/longitudinal-data-analysis/)





