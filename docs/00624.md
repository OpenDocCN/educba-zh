# 卷积神经网络

> 原文:[https://www.educba.com/convolutional-neural-networks/](https://www.educba.com/convolutional-neural-networks/)

![Convolutional Neural Networks](../Images/7ff8bcca7b5a6410d0232b2ce32965f5.png)

<noscript><img class="alignnone size-full wp-image-226601" src="../Images/7ff8bcca7b5a6410d0232b2ce32965f5.png" alt="Convolutional Neural Networks" width="900" height="500" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2019/10/Convolutional-Neural-Networks.png"/></noscript>

## 卷积神经网络简介

卷积神经网络，也称为 CNN 或 ConvNet，属于用于图像处理和可视化的人工神经网络类别。人工智能使用深度学习来执行任务。[神经网络是作为人脑中的神经元编程的硬件或软件。传统的神经网络仅将降低分辨率的图像作为输入。CNN 通过将他们的神经元排列为人类大脑的额叶来解决这个问题。与其他算法相比，CNN 上的预处理非常少。卷积是一种线性数学运算，用于 CNN。它在其一层中使用卷积而不是一般的矩阵乘法。](https://www.educba.com/what-is-neural-networks/)

### 卷积神经网络中的层

以下是卷积神经网络的层:

<small>Hadoop、数据科学、统计学&其他</small>

*   **图像输入层:**输入层给出输入(大部分是图像)，进行归一化。这里不得不提一下输入大小。
*   **卷积层:**在这一层进行卷积。首先，将图像分成感知器(算法)；创建局部场，导致将感知器压缩成作为大小为 m×n 的矩阵的特征图。
*   **非线性层:**这里特征图作为输入，激活图在激活函数的帮助下作为输出给出。激活函数通常被实现为 sigmoid 或双曲线正切函数。
*   **校正层:**CNN 的关键组成部分，这一层在不降低精度的情况下加快训练速度。它对激活映射执行元素绝对值操作。
*   **整流线性单元(ReLU):** ReLU 结合了 CNN 上的非线性和整流层。这将执行阈值运算，负值将被转换为零。然而，ReLU 不会改变输入的大小。
*   **汇集层:**汇集层也称为下采样层，因为它负责减小激活图的大小。相同长度的滤波器和步幅被应用于输入体积。该层忽略不太重要的数据；因此，图像识别是在较小的表示中完成的。这一层减少了过度拟合。因为使用池层减少了参数的数量，所以成本也降低了。输入被分成矩形池区域，计算最大值或平均值，从而返回最大值或平均值。最大池是一个受欢迎的。
*   **Dropout Layer:** 该层以给定的概率将输入层随机置零。在此操作之后，不同元素中的更多结果被丢弃。这一层也有助于减少过度拟合。这使得网络变得冗余。在这一层没有学习发生。该操作仅在训练期间进行。
*   **全连通层:**激活图是前几层的输出，在这一层转化为类概率分布。FC 层将输入乘以权重矩阵，并添加偏差向量。
*   **输出层:** FC 层之后是 softmax 和分类层。softmax 函数应用于输入。分类层计算分类问题的交叉熵和损失函数。
*   **回归层:**在这一层计算一半的均方误差。这一层应该在 FC 层之后。

### 卷积神经网络的体系结构

以下是卷积神经网络的架构:

#### 1.LeNet

LeNet 于 1998 年推出，用于文档中的光学和字符识别。它很小，非常适合在 CPU 上运行。LeNet 小巧，容易掌握。这是建立在三个主要思想上的:局部感受野共享权重和空间子采样。网络显示原始图像的最佳内部表示。它有三个卷积层、两个池层、一个全连接层和一个输出层。汇集层紧接着一个卷积层。

#### 2.AlexNet

AlexNet 是 2012 年开发的。这种架构在计算机视觉领域推广了 CNN。它有五个卷积层和三个全连接层，其中 ReLU 应用于每一层之后。它利用了这两层的优点，因为卷积层具有很少的参数和很长的计算时间，而对于全连接层则相反。数据扩充和剔除极大地减少了过度拟合。与 LeNet 相比，AlexNet 是一个池层，它不分隔更深、更大和更复杂的层。

#### 3.ZF 网

ZF 网开发于 2013 年，是 AlexNet 的修改版。中间卷积层的尺寸被扩大，并且第一卷积层的步幅和滤波器尺寸被做得更小。它只是认识到了 AlexNet 的不足，开发了一个更优越的。所有图层都和 AlexNet 一样。ZF 网调整 AlexNet 的层参数，如滤波器大小或步幅，使其降低错误率。

#### 4.谷歌网

这个架构是 2014 年开发的。初始层是核心概念。这一层覆盖了更大的区域，但是记录了图像的小信息。为了提高性能，GoogLeNet 中使用了九个初始模块。由于初始层容易过度拟合，这里使用了更多的非线性和更少的参数。最大池层用于连接前一层的输出。这个架构有 22 层，参数少了 12 倍。

这比 AlexNet 更准确，也更快。错误率相对较低。在末端使用平均池层，而不是完全连接的层。计算量减少，深度和宽度增加。许多 inception 模块被连接起来，以便更深入地研究架构。GoogLeNet 的表现优于 2014 年之前开发的所有其他架构。这种架构有几个后续版本。

#### 5.VGG 网

这是对 ZFNet 以及随后对 AlexNet 的改进。它有 16 层，包括 3×3 卷积层、2×2 汇集层和全连接层。这种架构采用最简单的网络结构，但它具有大多数参数。

#### 6\. ResNet

剩余网络架构是 2015 年开发的。它使用批量标准化，并跳过 FC 层的使用。这种架构使用 152 层，并使用跳跃连接。ResNet 现在大多用在[所有深度学习算法](https://www.educba.com/deep-learning-algorithms/)中。

### 结论

脸书用 CNN 做图片标签，用亚马逊做产品推荐，用谷歌搜索用户照片。所有这些都以更高的精度和效率完成。深度学习的进步达到了一个阶段，CNN 在许多方面得到了发展和帮助。随着 CNN 变得复杂，它有助于提高效率。

### 推荐文章

这是一个卷积神经网络指南。在这里，我们讨论卷积神经网络及其层以及架构的介绍。您也可以浏览我们推荐的其他文章，了解更多信息——

1.  [神经网络的分类](https://www.educba.com/classification-of-neural-network/)
2.  [机器学习 vs 神经网络](https://www.educba.com/machine-learning-vs-neural-network/)
3.  [神经网络算法概述](https://www.educba.com/neural-network-algorithms/)
4.  [递归神经网络(RNN)](https://www.educba.com/recurrent-neural-networks-rnn/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>