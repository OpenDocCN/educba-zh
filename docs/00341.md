# PySpark 点燃()

> 原文：<https://www.educba.com/pyspark-lit/>

![PySpark lit()](img/ecfd99137d5367fbcfa00e43f5bb7f92.png)



## PySpark lit 简介()

Pyspark lit()函数用于将新列添加到已经创建的数据框中；我们通过分配一个常量或文字值来创建一个新列。lit 函数以列的形式返回返回类型。我们可以通过导入 SQL 函数来导入 PySpark lit 的函数。假设我们需要在数据框中添加一个新列，那么 lit 函数就很有用。

### PySpark lit()是什么？

在 python 中，PySpark 模块提供了类似于使用数据框的处理。lit 函数用于通过向 PySpark 数据框中的列添加常数值来创建新列。它有助于连接 rdd，这是使用 py4j 库实现的。Pyspark 只不过是一个通过应用对大量非结构化和结构化数据的分析而开发的库。要在 python 中使用 lit 函数，我们需要 python 版本为 3.0，apache spark 版本为 3.1.1 或更高版本。

<small>网页开发、编程语言、软件测试&其他</small>

### PySpark lit()函数用在哪里？

当我们需要在创建的数据框中添加列时，我们可以使用 lit 函数。下面的语法显示了我们可以使用 lit 函数的地方，如下所示。

**语法:**

```
lit(val) .alias(name_of_column)
```

在上面的示例中，列名是我们要添加到数据集的列的名称。Value 只不过是我们添加到新列中的常量值。我们使用 lit 函数将新列添加到数据集中。

下面的例子显示了我们使用 lit 函数的情况。

在下面的例子中，我们正在导入 pyspark、spark session、col 和 lit 模块。我们正在定义 py 变量来创建数据框。创建数据框后，我们将列名 emp_code 列添加到数据框中。

**代码:**

```
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit
py = SparkSession.builder.appName('pyspark lit function').getOrCreate()
emp = [{'emp_id' : '11', 'emp_name' : 'ABC', 'emp_age' : 32},
   			{'emp_id' : '13', 'emp_name' : 'PQR', 'emp_age' : 36},
   			{'emp_id' : '15', 'emp_name' : 'XYZ', 'emp_age' : 41}]
pyspark = py.createDataFrame(emp)
lit_fun = pyspark.select(col("emp_id"),lit("21").alias("emp_code"))
lit_fun.show()
```

![PySpark lit() function Use 1](img/4b8bc80cb69624c35d14e8e638dbd7be.png)



在下面的示例中，我们向 emp 数据集添加了两列。我们将 emp_code 和 emp_addr 列添加到 emp 数据集，如下所示。

**代码:**

```
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit
py = SparkSession.builder.appName('pyspark lit function').getOrCreate()
emp = [{'emp_id' : '11', 'emp_name' : 'ABC', 'emp_age' : 32},
   			{'emp_id' : '13', 'emp_name' : 'PQR', 'emp_age' : 36},
   			{'emp_id' : '15', 'emp_name' : 'XYZ', 'emp_age' : 41}]
pyspark = py.createDataFrame(emp)
lit_fun = pyspark.select(col("emp_id"),lit("21").alias("emp_code"),lit("Pune").alias("emp_addr"))
lit_fun.show()
```

![PySpark lit() function Use 2](img/7e0f36dedf42e2586676f9e27bdd0f93.png)



### 如何使用 PySpark lit()？

基本上，我们使用 lit 函数向数据集添加一个具有常数值的新列。以下步骤显示了我们如何使用 lit 函数，如下所示。

为了使用 PySpark lit 函数，我们需要在我们的系统中安装 PySpark。

*   第一步，我们在系统中安装 PySpark 模块。我们使用 pip 命令安装这个模块，如下所示。

```
pip install pyspark
```

![Install Module](img/467dd7d37af4bf2477840a3c149474b7.png)



*   在本步骤中安装完模块后，我们使用 python 命令登录 python，如下所示。

```
python
```

![Python command ](img/af2858df574abc957efb0e27be99fd7d.png)



*   在 python 中登录后，在这一步中，我们导入 col、lit、PySpark 和 SparkSession 模块。我们使用 import 关键字导入所有模块。

```
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit
```

![Import All Module](img/09796cb23972fd4953d36ddd2e547e1b.png)



*   在本步骤中导入模块后，我们将应用程序名称创建为 pyspark lit function。我们将应用程序变量名定义为 py。

```
py = SparkSession.builder.appName('pyspark lit function').getOrCreate()
```

![Defining application variable ](img/846aa80426b3d7388924029bc2bed692.png)



*   在此步骤中，我们将创建螺柱数据框。我们创建的数据有三行，如下所示。

```
stud = [{'stud_id' : '41', 'stud_name' : 'AB', 'stud_age' : 12},
   {'stud_id' : '43', 'stud_name' : 'PQ', 'stud_age' : 6},
   {'stud_id' : '45', 'stud_name' : 'XY', 'stud_age' : 7}]
```

![stud data frame](img/5d81b4d704ac3ce0372b75aaa864e6af.png)



*   在这一步中，我们使用 stud 数据创建一个数据框，我们将数据框的变量定义为 lit_fun。

```
lit_fun = py.createDataFrame(stud)
```

![Variable of data frame](img/b638a691e17481319847fdfc0023f1e5.png)



*   在这一步中，我们使用 lit 函数将 stud_addr 列添加到 stud 数据集中。在添加新列时，我们也给该列赋予一个常量值。

```
lit_fun1 = lit_fun.select(col("stud_id"), lit("Pune").alias("stud_addr"))
lit_fun1.show()
```

![Add new Column](img/7fdc91888a4fa41caa3cfa092dffd990.png)



### 例子

以下是不同的例子:

#### 示例#1

在下面的例子中，我们添加了一个新的列名 stud_addr，如下所示。

**代码:**

```
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit
pyspark_lit = SparkSession.builder.appName (pyspark lit function').getOrCreate()
py_data = [("11", 110), ("13", 120), ("15", 130)]
col = ["stud_id", "stud_no"]
df = pyspark_lit.createDataFrame(data = py_data, schema = col)
df1 = df.select(col("stud_id"),col("stud_no"),lit("9").alias("stud_age"))
df1.show(truncate=False)
```

**输出:**

![PySpark lit() Example 1](img/62012cbccef4e8c3acb823c9fd7e1c76.png)



#### 实施例 2

这里我们有条件地添加一个新列。

**代码:**

```
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, lit
from pyspark.sql.functions import when
pyspark_fun = SparkSession.builder.appName ('pyspark lit function').getOrCreate()
data_fun = [("11", 110), ("13", 120), ("15", 130)]
data_col = ["stud_id", "stud_code"]
df = pyspark_fun.createDataFrame (data = data_fun, schema = data_col)
df2 = df.select (col("stud_id"), col("stud_code"), lit("9").alias("stud_age"))
df3 = df2.withColumn ("140", when(col("stud_code") >= 120 & col ("stud_code") <= 100, lit("105")).otherwise (lit("110")))
df3.show(truncate=False)
```

**输出:**

![PySpark lit() Example 2](img/32eb8262c7fd1f1621e78296d2bcad41.png)



### 关键要点

*   lit 函数用于将新列添加到已经在 pyspark 中创建的数据集中。
*   我们可以在数据框中添加新列时添加一个常量值。我们还可以在使用 lit 函数时添加条件。

### 常见问题解答

下面是提到的常见问题:

#### Q1。python 中的 lit 函数有什么用？

**回答:**基本上 python 中的 lit 函数是用来在已经创建好的数据框中增加一个新列的。

#### Q2。pyspark lit 函数中使用了哪些模块？

**回答:**我们在 python 中使用 lit 函数的时候，使用的是 col、lit、when、spark session、pyspark 模块。

#### Q3。pyspark 中的 lit 和 typedlit 函数有什么区别？

**答:**lit 和 typedlit 函数用于在已经创建的数据框中添加列。这两个函数在 pyspark 中做相同的工作。

### 结论

Lit 函数用于通过向 pyspark 数据框中的列添加常数值来创建新列。Pyspark lit 函数用于将新列添加到已经创建的数据框中，我们通过分配常量或文字值来创建新列。

### 推荐文章

这是 PySpark lit()的指南。在这里，我们讨论了 PySpark lit()函数的介绍和使用方法，并给出了不同的例子。您也可以看看以下文章，了解更多信息–

1.  [PySpark 管道](https://www.educba.com/pyspark-pipeline/)
2.  [PySpark 读取 CSV](https://www.educba.com/pyspark-read-csv/)
3.  [多列上的 PySpark 联接](https://www.educba.com/pyspark-join-on-multiple-columns/)
4.  [PySpark 给熊猫](https://www.educba.com/pyspark-to-pandas/)





