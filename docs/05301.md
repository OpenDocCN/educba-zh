# 火花纱

> 原文:[https://www.educba.com/spark-yarn/](https://www.educba.com/spark-yarn/)

![Spark YARN](../Images/d53aa4de9276cb036a16167f5bc3d185.png)

<noscript><img class="alignnone size-full wp-image-381021" src="../Images/d53aa4de9276cb036a16167f5bc3d185.png" alt="Spark YARN" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-YARN.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-YARN-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-YARN-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-YARN.jpg"/></noscript>

## 火花纱简介

Apache Spark YARN 或者是单个作业(作业是指 Spark 作业、hive 查询或任何类似的构造),或者是作业的 DAG(有向无环图)。Apache Spark YARN 是全局资源管理器中资源管理功能的一部分。以及每个应用程序的应用程序问题。纱线集群上的一个调度单元称为应用程序管理器。用于分布式工作负载的通用资源管理框架称为 YARN。YARN 支持许多不同的计算框架，如 Spark 和 Tez 以及 Map-reduce 函数。这是 Hadoop 系统的一部分。

### 句法

Apache Spark YARN 的语法如下:

<small>Hadoop、数据科学、统计学&其他</small>

`$ ./bin/spark-submit --class path.to.your.Class --master yarn --deploy-mode cluster [options] <app jar> [app options]`

### 阿帕奇火花纱的工作原理

了解集群和客户端模式:

Spark 的作业可以以两种方式在 YARN 上运行，即集群模式和客户端模式。选择合适的内存位置配置对于理解两种模式之间的差异非常重要。并按预期提交作业。

有两个部分需要激发。火花驱动器和火花执行器。Spark driver 调度执行器，而 Spark Executor 运行实际任务。

#### 客户端模式

创建了纱线的小应用。Spark 驱动程序运行在客户端模式，比如你的 pc。如果客户端关闭，作业将失败。Spark 执行器仍然运行在集群模式下，并且调度所有的任务。

#### 集群模式

YARN application master 有助于以集群模式封装 Spark 驱动程序。大多数东西都在集群内部运行。当您开始在笔记本电脑上运行作业时，即使您关闭了笔记本电脑，它仍然会运行。当 SparkPi 在 YARN 上运行时，它演示了如何使用 Spark 和 SparkPi 运行示例应用程序，并显示 Pi 近似计算的值。

![Apache Spark YARN works](../Images/12d056b5246d13c84d8a0cd12a754967.png)

<noscript><img class="alignnone size-full wp-image-380992" src="../Images/12d056b5246d13c84d8a0cd12a754967.png" alt="Apache Spark YARN works" width="391" height="350" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Apache-Spark-YARN-works.png 391w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Apache-Spark-YARN-works-300x269.png 300w" sizes="(max-width: 391px) 100vw, 391px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Apache-Spark-YARN-works.png"/></noscript>

应用程序会随着客户端的停止而失败，但是客户端模式非常适合交互式作业。集群模式更适合长时间运行的作业。

如何给 Apache Spark 纱线容器提供最大允许内存？

如果请求的内存超过允许的最大值，YARN 将拒绝创建容器，并且您的应用程序不会启动。

*   以下是单个容器允许的最大值，以兆字节为单位。

yarn . scheduler . max-allocation-MB 在＄HADOOP _ CONF _ DIR/yarn-site . XML 中获取其值

*   确保以下部分中为 Spark 内存分配配置的值低于最大值。
*   scheduler . maximum-allocation-Mb 本指南将使用样本值 1536。如果您的设置较低，请根据您的配置调整样本。

### 实现火花纱的示例

下面是提到的例子:

#### 示例#1

这就是在集群模式下启动 Spark 应用程序的方式:

**代码:**

`$ ./bin/spark-submit --class org.apache.spark.examples.SparkPi \
--master yarn \
--deploy-mode cluster \
--driver-memory 4g \
--executor-memory 2g \
--executor-cores 1 \
--queue thequeue \`

**解释:**上面启动了 YARN 客户端程序中的默认应用程序主机。然后，对于 Application Master，SparkPi 将作为子线程运行。客户端会定期轮询 Application master 以获取状态更新，并将其显示在控制台中。一旦应用程序运行完毕。客户端将退出。

以客户机模式启动 Spark 应用程序，但是必须用客户机替换集群。下面介绍了如何在客户端模式下运行 spark-shell:

`$ ./bin/spark-shell --master yarn --deploy-mode client`

#### 实施例 2

如何添加其他罐子:

驱动程序运行在与集群模式下的客户端不同的机器上。这就是为什么 spark context.add jar 不能开箱即用地处理客户端本地文件的原因。对于 SparkContext.addjar，需要使客户机上的文件可用。为此，我们需要在启动命令中包含选项—jars。

**代码:**

`$ ./bin/spark-submit --class my.main.Class \
--master yarn \
--deploy-mode cluster \
--jars my-other-jar.jar,my-other-other-jar.jar \
my-main-jar.jar \
app_arg1 app_arg2`

**输出:**

![add Other Jars](../Images/f2394878c847835da56c272481688072.png)

<noscript><img class="alignnone wp-image-380096 size-full" src="../Images/f2394878c847835da56c272481688072.png" alt="add Other Jars" width="601" height="97" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/spark-yarn2.jpg 601w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/spark-yarn2-300x48.jpg 300w" sizes="(max-width: 601px) 100vw, 601px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/spark-yarn2.jpg"/></noscript>

![submit](../Images/305c1da38a88a1c85f52328db218daf1.png)

<noscript><img class="alignnone wp-image-380097 size-full" src="../Images/305c1da38a88a1c85f52328db218daf1.png" alt="submit" width="605" height="92" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/spark-yarn3.jpg 605w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/spark-yarn3-300x46.jpg 300w" sizes="(max-width: 605px) 100vw, 605px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/spark-yarn3.jpg"/></noscript>

### 结论

在本文中，我们讨论了 Spark 资源规划原则，并在为 Spark 应用程序进行资源调优之前了解了用例性能和纱线资源配置。我们按照一定的步骤来计算 Spark 应用程序的资源(执行器、内核和内存)。结果如下:Spark 应用程序的数据帧实现从 1.8 分钟到 1.3 分钟的显著性能提升。Spark 应用程序的 RDD 实施速度提高了两倍，从 22 分钟缩短到 11 分钟。

### 推荐文章

这是一个火花纱指南。在这里，我们讨论了火花纱的介绍，语法，它是如何工作的，更好地理解的例子。您也可以浏览我们的其他相关文章，了解更多信息——

1.  [火花版本](https://www.educba.com/spark-versions/)
2.  [火花命令](https://www.educba.com/spark-commands/)
3.  [火花阶段](https://www.educba.com/spark-stages/)
4.  [阿帕奇火花](https://www.educba.com/apache-spark/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>