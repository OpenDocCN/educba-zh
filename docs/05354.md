# PySpark 别名

> 原文：<https://www.educba.com/pyspark-alias/>

![PySpark Alias](img/f5d94d967761bbdf580ac893e2444e69.png)



## PySpark 别名介绍

PySpark Alias 是 PySpark 中的一个函数，用于为一个列或表创建一个特殊的签名，该签名通常可读性更强、更短。我们可以将 more 作为 PySpark 数据框/数据集中的表或列的派生名称。别名提供了对 PySpark 中作为别名的列/表的某些属性的访问。别名功能可用于某些连接的情况，在这种情况下，存在自连接的条件，即在数据帧中处理更多的表或列。别名为特定的列和表提供了一个新的名称，属性可以在它之外使用。

### PySpark 别名的语法

下面给出了提到的语法:

<small>网页开发、编程语言、软件测试&其他</small>

```
from pyspark.sql.functions import col
b = b.select(col("ID").alias("New_IDd"))
b.show()
```

**说明:**

*   **b:** 要使用的 PySpark 数据帧。
*   **alias(" ":**用新的列名重命名数据框的列的函数。
*   **select(col(" Column name ")):**用于别名的列。

**输出:**

![pyspark 1](img/6de7afe3957cf21ad327f8b76055c47b.png)



### PySpark 中 Alias 的使用

下面给出了 PySpark 中 alias 的工作方式:

*   该函数只是给出了一个新的名称作为引用，可以进一步用于 PySpark 中的数据框。别名可用于重命名 PySpark 中的列。一旦指定了别名，特定表格或数据框的属性被指定，就可以使用它来访问相同的属性。使用 join 操作时，别名可用于基于表列操作来连接列。
*   alias 函数可以用来替代 PySpark 中的列或表，还可以用来访问它的所有属性。它们就像一个临时的名字。这使得列名更容易访问。当列名或表名足够大时，可以使用别名。别名可称为 PySpark 数据框中表或列的相关名称。

### PySpark 别名示例

下面是提到的例子:

让我们从在 PySpark 中创建简单数据开始。

**代码:**

```
data1 = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tina','ID':2.48,'Add':'IND'},{'Name':' ','ID':22.22, 'Add':'USA'},{'Name':'Joe','ID':5.33,'Add':'INA'}]
```

创建一个示例数据，字段为 Name、ID 和 ADD。

```
a = sc.parallelize(data1)
```

RDD 是使用 sc 创建的。并行化。

```
b = spark.createDataFrame(a)
b.show()
```

使用 Spark.createDataFrame 创建了数据框。

**输出:**

![Spark.createDataFrame](img/3e193b1a035381ada5d7394f7de51eb6.png)



别名函数来覆盖数据帧。

为将列 ID 的名称更改为新名称 New_Id 而发出的别名。

**代码:**

```
b = b.select(col("ID").alias("New_ID")).show()
```

**输出:**

![pyspark alias 3](img/ca8851ba4e268232c17b6f25708b5260.png)



通过别名化到新的数据框或名称，可以使用该数据框。

**代码:**

```
b.alias("New_Name")
```

**输出:**

![new data frame or name](img/fe2a43144c9cdfcf5e78dcc4d7badc91.png)



别名函数也可用于更改现有数据框中的列名。

在上面的数据框中，通过使用 alias 函数可以将同一列重命名为新列 New_id，并且结果可以将新列作为数据。

**代码:**

```
b.select("add",col("Id").alias("New_ID"),"Name").show()
```

**输出:**

![pyspark alias 5](img/5f8011c936c340bd844b39b10cd47b3e.png)



在使用 PySpark SQL 操作时也可以使用 alias 函数。SQL 操作在用于 join 操作或 select 操作时通常为表和列值起别名，可以通过使用点(.)运算符。表名。列名用于访问表中的特定列，同样，别名 A.columname 也可以在 PySpark SQL 函数中用于相同的目的。

别名可以简单地完成，将名称放在需要别名的元素之后，或者简单地使用表名作为函数，后跟别名。

**代码:**

```
Spark.sql("Select * from Demo d where d.id = "123"")
```

该示例显示了表 Demo 的别名 d，它可以访问表 Demo 的所有元素，因此条件可以写成等同于 Demo.id 的 d.id。

**Note:** It is a function used to rename a column in data frame in PySpark. It can be used in join operation. It makes the column or a table in a readable and easy form. It is a temporary name given to a Data Frame/Column or table in PySpark. It inherits all the property of the element it is referenced to.

### 结论

从上面的文章中，我们看到了 PySpark 中别名操作的使用。通过各种示例和分类，我们试图理解 PySpark 中的 Alias 方法是如何工作的，以及在编程级别使用了什么。我们还看到了 PySpark 数据框架中的 Alias 的内部工作和优势，以及它在各种编程目的中的使用。此外，语法和例子帮助我们更准确地理解函数。

### 推荐文章

这是 PySpark 别名指南。这里我们讨论 PySpark 中 alias 的介绍、工作原理和示例，以便更好地理解。您也可以看看以下文章，了解更多信息–

1.  [py 帕克集团](https://www.educba.com/pyspark-groupby/)
2.  [pypark 群表计数](https://www.educba.com/pyspark-groupby-count/)
3.  [PySpark 联盟](https://www.educba.com/pyspark-union/)
4.  [PySpark 地图](https://www.educba.com/pyspark-map/)





