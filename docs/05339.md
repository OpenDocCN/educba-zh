# PySpark 窗口函数

> 原文:[https://www.educba.com/pyspark-window-functions/](https://www.educba.com/pyspark-window-functions/)

![PySpark Window Functions](../Images/b3d56308b3f4a9e0c11d5e6bc48ec152.png)

<noscript><img class="alignnone size-full wp-image-461799" src="../Images/b3d56308b3f4a9e0c11d5e6bc48ec152.png" alt="PySpark Window Functions" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions.jpg"/></noscript>

## PySpark 窗口简介

PySpark window 是一个 Spark 函数，用来计算带有数据的窗口函数。正常的窗口函数包括用于对输入行进行操作并生成结果的函数，如秩、行号。它也被称为窗口或窗口函数，通常对一组行执行计算，这一行可以称为帧。聚合或应用函数后，将为每一行返回一个新值，该值将与给定的值相对应。我们还可以在 PySpark 数据框架上使用 SQL 相关的查询，并应用同样的方法。窗口操作作用于一组行，并通过应用聚合函数为每个输入行返回一个值。有几种窗口操作可以应用于数据来计算结果。

### 带示例的窗口函数

下面给出的是带示例的窗口函数:

<small>网页开发、编程语言、软件测试&其他</small>

#### 1.排名函数

这些是 PySpark 中的窗口函数，用于对数据进行排序。有几个用于处理数据和计算结果的排名函数。

让我们详细检查一些排名功能。

**a. ROW_NUMBER():** 这给出了该行的行号。它从 1 开始，行数根据分区元素不断增加。

让我们从制作一个简单的数据框开始，我们将尝试在这个数据框上实现窗口功能。考虑了一个有关系和所有学期成绩的学生的数据框架，并在此基础上制作了数据框架。

**代码:**

`data1 = (("Bob", "IT", 4500), \
("Maria", "IT", 4600), \
("James", "IT", 3850), \
("Maria", "HR", 4500), \
("James", "IT", 4500), \
("Sam", "HR", 3300), \
("Jen", "HR", 3900), \
("Jeff", "Marketing", 4500), \
("Anand", "Marketing", 2000),\
("Shaid", "IT", 3850) \
)
col= ["Name", "MBA_Stream", "SEM_MARKS"] >>> b = spark.createDataFrame(data1,col)`

create data 根据列和数据创建数据框。

`>>> b.printSchema()
>>> from pyspark.sql.window import Window`

用于窗口操作的窗口函数。

`>> from pyspark.sql.functions import row_number`

Row_number 窗口函数计算基于分区的行数。

`>> w = Window.partitionBy("MBA_Stream").orderBy("Name")`

要使用的列和要用于的 order by 操作。

`>> b.withColumn("Windowfunc_row",row_number().over(w)).show()`

这将创建一个数据框，并使用 row_number 窗口函数来计算给定数据框的 row_number。

**输出:**

![PySpark Window Functions 1](../Images/8f4b9ab3bd7584c48922e32e02695aca.png)

<noscript><img class="alignnone wp-image-461593 size-full" src="../Images/8f4b9ab3bd7584c48922e32e02695aca.png" alt="PySpark Window Functions 1" width="470" height="736" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-1.jpg 470w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-1-192x300.jpg 192w" sizes="(max-width: 470px) 100vw, 470px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-1.jpg"/></noscript>

![PySpark Window Functions 3](../Images/f2d9146d7574561aca06b983376fc811.png)

<noscript><img class="alignnone wp-image-461595 size-full" src="../Images/f2d9146d7574561aca06b983376fc811.png" alt="PySpark Window Functions 3" width="649" height="341" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-2.jpg 649w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-2-300x158.jpg 300w" sizes="(max-width: 649px) 100vw, 649px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-2.jpg"/></noscript>

**b .秩函数:**该函数用于提供给定数据帧的秩。这是一种窗口操作，用于根据数据框创建等级。

我们将尝试从 SQL Rank 函数中导入 Rank 函数。

**代码:**

`>> from pyspark.sql.functions import rank`

这将导入排名函数，我们可以在其中计算排名。

`>> b.withColumn("Window_Rank",rank().over(w)).show()`

这将按照建议对给定条件下的元素进行排序。

**输出:**

![RANK](../Images/dd8b0551f57b78a9315c7f6d87f414f6.png)

<noscript><img class="alignnone wp-image-461597 size-full" src="../Images/dd8b0551f57b78a9315c7f6d87f414f6.png" alt="RANK" width="662" height="384" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-3JPG.jpg 662w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-3JPG-300x174.jpg 300w" sizes="(max-width: 662px) 100vw, 662px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-3JPG.jpg"/></noscript>

**c. DENSE-RANK 函数:**类似于 RANK 函数，这也用于对元素进行排序，但是不同之处在于排序没有任何间隙。

我们将引入稠密秩函数。

**代码:**

`>>> from pyspark.sql.functions import dense_rank
>>> b.withColumn("Window_DeneRank",dense_rank().over(w)).show()`

**输出:**

![DENSE-RANK](../Images/943c0d757d0d27b9bc17e7b461f6310f.png)

<noscript><img class="alignnone wp-image-461598 size-full" src="../Images/943c0d757d0d27b9bc17e7b461f6310f.png" alt="DENSE-RANK" width="794" height="347" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-4JPG.jpg 794w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-4JPG-300x131.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-4JPG-768x336.jpg 768w" sizes="(max-width: 794px) 100vw, 794px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-4JPG.jpg"/></noscript>

**d. NTILE 函数:**它返回结果的相对排名，它有一个参数值，排名元素将位于其中。

**举例:**

**代码:**

`>>> from pyspark.sql.functions import ntile
>>> b.withColumn("Window_Ntile",ntile(2).over(w)).show()`

这里我们给出的参数是 2，它只根据这个值对函数进行排序。

**输出:**

![NTILE](../Images/ed3552637c081e549eef60b9445868f4.png)

<noscript><img class="alignnone wp-image-461601 size-full" src="../Images/ed3552637c081e549eef60b9445868f4.png" alt="NTILE" width="689" height="369" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-5JPG.jpg 689w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-5JPG-300x161.jpg 300w" sizes="(max-width: 689px) 100vw, 689px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-5JPG.jpg"/></noscript>

#### 2.分析功能

这些是用于数据流分析的窗口函数。

让我们来看看一些分析功能:

**a. Cume_dist()函数:**给出分区上值的累积分布。

**代码:**

`>>> b.withColumn("Window_cumeDist",cume_dist().over(w)).show()`

**输出:**

![PySpark Window Functions 6JPG](../Images/0474574c2f1463abcbbef7940789090e.png)

<noscript><img class="alignnone wp-image-461602 size-full" src="../Images/0474574c2f1463abcbbef7940789090e.png" alt="PySpark Window Functions 6JPG" width="760" height="378" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-6JPG.jpg 760w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-6JPG-300x149.jpg 300w" sizes="(max-width: 760px) 100vw, 760px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-6JPG.jpg"/></noscript>

**b. LAG 函数:**这是一个窗口函数，用于从定义的偏移值开始访问之前的数据。

**举例:**

**代码:**

`>>> b.withColumn("Window_lag",lag("SEM_MARKS",1).over(w)).show()`

这给出了所用列的先前值。

同样的偏移量可以调整，我们可以取需要的值。

`>>> b.withColumn("Window_lag",lag("SEM_MARKS",2).over(w)).show()`

**输出:**

![LAG](../Images/2bce5f4a1af7b4c5a782c03b46de2eea.png)

<noscript><img class="alignnone wp-image-461603 size-full" src="../Images/2bce5f4a1af7b4c5a782c03b46de2eea.png" alt="LAG" width="807" height="764" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-7JPG.jpg 807w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-7JPG-300x284.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-7JPG-768x727.jpg 768w" sizes="(max-width: 807px) 100vw, 807px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-7JPG.jpg"/></noscript>

**c. LEAD Function:** 这是一个窗口函数，用于从定义的偏移值开始访问下一个数据。

**代码:**

`>>> from pyspark.sql.functions import lead
>>> b.withColumn("Window_lead",lead("SEM_MARKS",1).over(w)).show()`

**输出:**

![LEAD](../Images/cb3f8945cf7783cc3bc44d9a823fca7c.png)

<noscript><img class="alignnone wp-image-461605 size-full" src="../Images/cb3f8945cf7783cc3bc44d9a823fca7c.png" alt="LEAD" width="816" height="392" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-8JPG.jpg 816w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-8JPG-300x144.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-8JPG-768x369.jpg 768w" sizes="(max-width: 816px) 100vw, 816px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/03/PySpark-Window-Functions-8JPG.jpg"/></noscript>

从这里我们可以看到 PySpark 中不同窗口函数的使用。

### 结论

从上面的文章中我们看到了 PySpark 中窗口函数的使用。从各种例子和分类中，我们试图理解窗口方法在 PySpark 中是如何工作的，以及在编程级别中使用了什么。工作模式使我们正确理解了职能的内涵，并帮助我们获得了更多的相关知识。语法有助于检查所使用的参数和函数的功能知识。我们还看到了 PySpark 的内部工作原理和在 Spark 数据框架中使用 Window 函数的优点，以及它在各种编程目的中的用法。语法和例子也帮助我们更精确地理解这个函数。

### 推荐文章

这是 PySpark 窗口函数的指南。这里我们分别用例子讨论介绍和窗口功能。您也可以看看以下文章，了解更多信息–

1.  [星火中的 RDD](https://www.educba.com/rdd-in-spark/)
2.  [火花广播](https://www.educba.com/spark-broadcast/)
3.  [火花上下文](https://www.educba.com/sparkcontext/)
4.  [PySpark 加入](https://www.educba.com/pyspark-join/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>