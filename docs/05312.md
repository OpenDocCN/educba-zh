# 火花累加器

> 原文:[https://www.educba.com/spark-accumulator/](https://www.educba.com/spark-accumulator/)

![Spark-Accumulator](../Images/e3a205d1c0ef3a48980a3e5198db9a20.png)

<noscript><img class="alignnone size-full wp-image-378031" src="../Images/e3a205d1c0ef3a48980a3e5198db9a20.png" alt="Spark-Accumulator" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Accumulator.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Accumulator-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Accumulator-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Accumulator.jpg"/></noscript>

## 火花蓄压器简介

Apache Spark 使用共享变量。当驱动程序向集群执行器发送任务时，集群的每个节点都会收到共享变量的副本。Apache Spark 支持两种基本类型的共享变量——累加器和广播。Apache Spark 应用广泛，是一个开源的集群计算框架。这带来了计算机器学习、API 流和图形处理算法等功能。通过相关运算添加的变量是累加器。实现求和与计数器是累加器任务的一个例子，还有许多类似的任务。spark 对数字类型的支持比任何其他类型都要容易，但是程序员可以将这种支持添加到其他类型中。

**语法:**

<small>Hadoop、数据科学、统计学&其他</small>

上面的代码分享了 PySpark 的类累加器的细节。

`val acc = sc.accumulator(v)`

最初，当执行求和 r 计数操作时，更优选地将 v 设置为零。

### 我们为什么要用火花蓄电池？

当用户想要对数据执行通信或关联操作时，我们使用 Spark 累加器。这些可以不带名称或带名称创建。Sparks 用户界面有助于查看用 accumulator 创建的名称，这些也有助于理解运行阶段的进度。通过调用 SparkContext.accumulator(v ),可以创建以初始值为 v 的累加器，就像 Spark broadcast 一样。用于实现 MapReduce 函数中的求和及计数器运算。Python 中不支持累加器。

**代码:**

`package org.spark.accumulator.crowd.now.aggregator.sample2
var lalaLines: Int = 0
sc.textFile(“some log file”, 4)
.forech { line =>
if (line.length() == 0) lalaLines += 1
}
println (s “ Lala Lines are from the above code = $lalaLines”)`

在上面的代码中，当打印空行代码输出时，该值将为零。Spark 将代码转移到每个执行器，变量对于该执行器来说是局部的，并且最新和更新的值不会反馈给驱动程序。将空白行作为累加器可以解决上述问题。这将有助于更新每个执行器中每个变量的所有更改。

上面的代码是这样写的:

**代码:**

`package org.spark.accumulator.crowd.now.aggregator.sample2
var lalaLines = sc.accumulator(, “lala Lines”)
sc.textFile(“some log file”, 4)
.forech { line =>
if (line.length() == 0) lalaLines += 1
}
println (s “\tlala Lines are from the above code = $lalaLines.value”)
This code makes sure that the accumulator blankLine is up to date across each executor and relays back to the driver.`

### 火花蓄电池是如何工作的？

broadcast 变量允许 Spark 的开发人员在不同的节点上保存一个安全的只读缓存变量。与所需的任务，只有航运副本而已。无需浪费大量时间和传输网络输入和输出，它们可用于为节点提供输入数据集的大量副本。Spark 可以使用各种累加器算法来分配广播变量，这可能会大大降低通信成本。

执行 Spark 的操作有不同的阶段。然后通过操作——洗牌来分离这些阶段。在每一级 Spark 累加器中，公共数据需要自动保存在缓存中，并且应该被序列化，在每个任务运行之前，每个节点将再次从缓存中反序列化。因此，如果广播的变量是显式创建的，则需要使用相同的数据执行多个分阶段的任务，应该执行上述操作。

上面提到的通过包装函数 SparkConext.accumulator **，**创建广播变量，其代码为:

**代码:**

`val accum = sc.accumulator(0)
accum: spark.Accumulator[Int] = 0
sc.parallelize(Array(1, 2, 3, 4)).foreach(x => accum += x)
accum.value
res2: Int = 20
package org.spark.accumulator.crowd.now.aggregator.sample2
object Boot {
import util.is
def main(args: Array[String]): Unit = {
val sparkConfigiration = new Spark.Configuration(true)
.setMaster_("L[4]")
.setNameOfApp("Analyzer Spark")
val sparkContext = new Spark.Context(spark.Configuration)
val httpStatusList = sparkContext broadcast populateHttpStatusList
val Info_http = sparkContext accumulator(0, "HTTP a")
val Success_http = sparkContext accumulator(0, "HTTP b")
val Redirect_http = sparkContext accumulator(0, "HTTP c")
val Client.Error_http = sparkContext accumulator(0, "HTTP d")
val Server.Error_http = sparkContext accumulator(0, "HTTP e")
sparkContext.tf(gClass.gRes("log").gPath,
println("THE_START")
println("HttpStatusCodes are going to be printed in result from access the log parse")
println("Http Status Info")
println(“Status Success")
println("Status Redirect")
println("Client Error")
println(“Server Error")
println("THE_END")
spark.Context.stop()
}
}
}`

广播的变量称为值，它存储用户数据。该变量也返回值 broadcast。

`accumulator_ = sc.accumulator(0)
rdd = sc.parallelize([1, 2, 3, 4])
def f(x):
global accumulator_
accum += x
rdd.foreach(f)
accum.value`

累加器命令行如下所示:

`$SPARK_HOME/bin/spark-submit accumulator.py`

**输出:**

![Spark Accumulator Example](../Images/1320f1d3688e07f73d932ea961419ef4.png)

<noscript><img class="alignnone size-full wp-image-377088" src="../Images/1320f1d3688e07f73d932ea961419ef4.png" alt="Spark Accumulator Example" width="200" height="55" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Accumulator-Example.png"/></noscript>

### 火花蓄压器的优点和用途

内存访问非常直接。

1.  垃圾值在处理开销中收集得最少。
2.  内存格式是紧凑的柱状。
3.  查询催化剂优化。
4.  代码生成是整个阶段。
5.  通过数据集编译切片类型相对于数据框的优势。

### 结论

我们已经看到了火花累加器的概念。Spark 使用共享变量，用于处理和并行。对于信息聚合、通信关联和操作，使用累加器变量。在 map-reduce 中，为了对计数器或运算求和，我们可以使用累加器。而在 spark 中，变量是可变的。累加器的值不能被执行者读取。但是只有驱动程序可以。Map reduce java 中的计数器与此类似。

### 推荐文章

这是一个火花累加器的指南。在这里，我们讨论火花累加器的介绍，以及它如何工作，其优势和用途。您也可以浏览我们推荐的其他文章，了解更多信息——

1.  [JavaScript 数学函数(示例)](https://www.educba.com/javascript-math-functions/)
2.  [9 大类 Java 编译器](https://www.educba.com/java-compilers/)
3.  [Android 架构|什么是 Android 架构？](https://www.educba.com/android-architecture/)
4.  [9 大安卓广告拦截器](https://www.educba.com/android-ad-blocker/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>