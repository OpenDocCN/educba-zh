# Python BeautifulSoup

> 原文:[https://www.educba.com/python-beautifulsoup/](https://www.educba.com/python-beautifulsoup/)

![Python BeautifulSoup](../Images/3a9de381f57c4c21d15ca61e13c9257d.png)

<noscript><img class="alignnone size-full wp-image-378085" src="../Images/3a9de381f57c4c21d15ca61e13c9257d.png" alt="Python BeautifulSoup" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Python-BeautifulSoup.jpg.webp 900w,https://cdn.educba.com/academy/wp-content/uploads/2020/06/Python-BeautifulSoup-300x167.jpg.webp 300w,https://cdn.educba.com/academy/wp-content/uploads/2020/06/Python-BeautifulSoup-768x427.jpg.webp 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Python-BeautifulSoup.jpg.webp"/></noscript>

## Python BeautifulSoup 简介

BeautifulSoup 减少了工作时的人力和时间。Python BeautifulSoup 是一个用于从 HTML 和 XML 等标记语言文件中提取数据的 Python 库。它还提供了产生导航、修改和搜索必要文件的类似方法。也用于使用您最喜欢的解析器进行树解析。在本教程中，让我们了解 beautifulsoup 是如何工作的，以及个人如何实现自己的梦想。还有，当它违背你的命令时行动的决心。当你被直接提供下载时，当你寻找的一些网页显示你的研究的相关数据时，这帮助你克服这样的问题，这基本上是网络抓取。

### Python BeautifulSoup 的安装

安装 python beautifulsoup 的说明如下:

<small>网页开发、编程语言、软件测试&其他</small>

```
pip install beautifulsoup4
pip install lxml
sudo pip install lxml
pip install future
sudo pip install future 
```

**注意:**如果你已经有了 pip 之类的 Python 安装程序，这就变得更容易了。

### 通过网页访问 HTML

```
import requests
URL = ”https://www.educba.com/software-development/”
r = requests.get(URL)
print(r.content) 
```

让我为你详细说明每一段代码:

*   导入库请求。
*   通过指定网址抓取你想要的网页。
*   向指定的 URL 发送 HTTP 请求并保存响应。响应对象称为 r。
*   r.content 打印将在稍后完成，它是网页的原始 HTML 内容，不是“字符串”类型。

### 内容 HTML 的解析

```
import requests
from bs4 import BeautifulSoup
URL = ”https://www.educba.com/software-development/”
r = requests.get(URL)
soup = BeautifulSoup(r.content, ‘html5lib’ )
print = (soup.prettify()) 
```

BeautifulSoup 库有一个非常好的东西:可以构建 HTML 解析库，如 html.parser、lxml、html5lib 等。

### 了解 Python BeautifulSoup(带示例)

下面给出了 python beautifulsoup better 的例子:

**一个简单的快速抓取**:它只不过是使用请求来请求数据，并提供特定 HTML 文件的 URL。其次，提供一些正则表达式并从 HTML 文件中提取数据。请注意，这个 HTML 文件充满了姓名、电子邮件和电话号码，而且都是刚刚生成的数据。这一切都只是垃圾，这是真实的。

这里所做的就是创建一个正则表达式，它匹配我在文件中找到的数据的电话号码，并且只匹配一个非常基本的电子邮件格式。这不是一个伟大的正则表达式。为了从网页中抓取 HTML，让我们编写代码。让我们看看如何解析它。下面的代码发送一个获取所需网页的请求，并用 HTML 创建一个 beautifulsoup 对象。

```
import requests
from bs4 import BeautifulSoup
vgm_url = ‘https://www.vgmusic.com/music/console/nintendo/nes/’
html_text = requests.get(vgm_url).text
soup = BeautifulSoup(html_text,’html.parser’) 
```

soup 对象使用 HTML 搜索和导航您想要的数据。find 和 findall 是最强大的模块之一。在只有一个元素的地方，您知道 body 标签有 soup.find()。而 soup.findall()用于 web 抓取的冒险。使用它，迭代和打印所有超链接的 URL 就完成了。此外，标记属性和使用 findall 提供不同的参数就像正则表达式一样，可以根据您的需要进行具体更改。

在编写解析代码之前，我们将研究浏览器正在呈现的 HTML。模式识别和实验是一个小的网络抓取所需要的，因为每个网页本身都是不同的。让我们下载一堆 MIDI 文件。通过网页编写代码来解析它通常有助于现代浏览器中可用的开发工具。检查 HTML 将帮助您确定是否可以通过编程方式访问数据。

我们将使用 findall()方法，通过正则表达式遍历链接，因为我们的目标是通过过滤掉没有括号的文本，只获得包含 MIDI 文件的链接。这允许我们排除所有的混音和重复。

```
import re
import requests
from bs4 import BeautifulSoup
vgm_url = ‘https://www.vgmusic.com/music/console/nintendo/nes/’
html_text = requests.get(vgm_url).text
soup = BeautifulSoup(html_text,’html.parser’)
if __name__ == '__main__':
attrs = {
'href' : re.compile(r'\.mid$')
}
tracks = soup.find_all('a', attrs=attrs, string=re.compile(r'^((?!\().)*$'))
count = 0
for track in tracks:
print(track)
count += 1
print(len(tracks)) 
```

它帮助我们过滤掉所有的 MIDI 文件，并了解如何下载它们。

同样，我们需要考虑迭代所有的 MIDI 文件，并通过给出代码来理解如何下载它们。添加一个小的 donwload_track 并调用上面的函数帮助我们通过迭代所有的 MIDI 文件来下载文件。

```
import re
import requests
from bs4 import BeautifulSoup
vgm_url = ‘https://www.vgmusic.com/music/console/nintendo/nes/’
html_text = requests.get(vgm_url).text
soup = BeautifulSoup(html_text,’html.parser’)
def download_track(count, track_element):
#Get the title of the track from the HTML element
track_title = track_element.text.strip().replace('/','-')
download_url = '{}{}'.format(vgm_url, track_element['href'])
file_name = '{}_{}.mid'.format(count,track_title)
#Download the track
r = requests.get(download_url,allow_redirects=True)
with open(file_name, 'wb') as f:
f.write(r.content)
#Print to the console to keep track of how the scraping is coming along.
print('Downloaded: {}'.format(track_title, download_url))
if __name__ == '__main__':
attrs = {
'href' : re.compile(r'\.mid$')
}
tracks = soup.find_all('a', attrs=attrs, string=re.compile(r'^((?!\().)*$'))
count = 0
for track in tracks:
print(track)
count += 1
print(len(tracks)) 
```

传递 BeautifulSoup 的对象，该对象表示 HTML 并链接到一个带有唯一编号的 MIDI 文件，使用文件名并克服可能的命名冲突。

### 结论

如果你想从任何网页中获取一些数据，BeautifulSoup 就是为你准备的。它帮助你克服网页抓取的代码障碍。一个 Python 库，帮助从 XML 和 HTML 等标记语言中获取数据。使用 BeautifulSoup 对象简单地创建了数据的内容解析。

### 推荐文章

这是一个 Python BeautifulSoup 的指南。在这里，我们还将讨论 python beautifulsoup 的介绍和安装，以及一个示例及其代码实现。您也可以看看以下文章，了解更多信息–

1.  [Python 计数器](https://www.educba.com/python-counter/)
2.  [Python 并发](https://www.educba.com/python-concurrency/)
3.  [Python argparse](https://www.educba.com/python-argparse/)
4.  [Python 唯一列表](https://www.educba.com/python-unique-list/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>