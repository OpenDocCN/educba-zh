# PySpark Sort

> 原文:[https://www.educba.com/pyspark-sort/](https://www.educba.com/pyspark-sort/)

![PySpark Sort](../Images/45c918a6f8cecda5f0d107e62bfcbed0.png)

<noscript><img class="alignnone size-full wp-image-500894" src="../Images/45c918a6f8cecda5f0d107e62bfcbed0.png" alt="PySpark Sort" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort.jpg"/></noscript>

## PySpark 排序简介

PySpark Sort 是一个 PySpark 函数，用于对 PySpark 数据模型中的一列或多列进行排序。这是一个排序函数，它获取列值并相应地对值进行排序，排序函数的结果在每个分区中定义，排序顺序可以是降序和升序。默认情况下，排序按升序进行。Sort 函数用于数据分析，因为返回的数据是按照需求定义的顺序排列的。

该函数可用于数据分析，因为它按所需的顺序对数据进行排序。在本文中，我们将尝试分析使用 PySpark 排序操作 PYSPARK 的各种方法。

<small>网页开发、编程语言、软件测试&其他</small>

让我们试着更详细地了解一下。

**语法:**

该函数的语法是:

`b = spark.createDataFrame(a)
>>> b.sort("Name","Sal").show()`

排序函数与数据框中的列名一起使用，根据排序要求，列名可以是单个或多个。

B:-要使用的数据帧。

**截图:**

![PySpark Sort 1](../Images/13951598dac8608a3c2ab5d918a2d59f.png)

<noscript><img class="alignnone size-full wp-image-500500" src="../Images/13951598dac8608a3c2ab5d918a2d59f.png" alt="PySpark Sort 1" width="293" height="95" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-1.png"/></noscript>

### 在 PySpark 工作

该函数采用排序算法，根据提供的输入列对数据进行排序。它占用列值，并根据提供的条件对数据进行排序。根据提供的条件值，排序条件可以是升序或降序。

根据相应的值检查列值，并对数据进行排序。它可以接受单个列值，也可以接受多个列值，从而对数据进行排序。这是一个多阶段的过程，因此在对数据进行排序的同时，还要对数据进行洗牌。它不会对数据进行重新分区，只保留当前分区。

PySpark 有消除排序函数的概念，这基本上是一种使用的优化技术，它消除了对最终操作没有影响的排序函数，从而在对 PySpark 模型中的数据进行排序时降低了操作成本。让我们检查创建并使用一些编码示例。

### 例子

让我们看一些例子来说明这种操作是如何进行的。让我们从在 PySpark 中创建一个样本数据框开始。

`>>> data1 = [{'Name':'Jhon','Sal':25000,'Add':'USA'},{'Name':'Joe','Sal':30000,'Add':'USA'},{'Name':'Tina','Sal':22000,'Add':'IND'},{'Name':'Jhon','Sal':15000,'Add':'USA'}]`

该数据包含姓名、工资和地址，将用作创建数据框的样本数据。

`>>> a = sc.parallelize(data1)`

sc。并行化将用于使用给定数据创建 RDD。

`>>> b = spark.createDataFrame(a)`

创建后，我们将使用 createDataFrame 方法来创建数据框。

这是数据框的外观。

`>>> b.show()`

**截图:**

![Output 2](../Images/c72c3122f712094cdea9c0f4f28a8a5e.png)

<noscript><img class="alignnone wp-image-500501 size-full" src="../Images/c72c3122f712094cdea9c0f4f28a8a5e.png" alt="Output 2" width="619" height="99" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-2.png 619w, https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-2-300x48.png 300w" sizes="(max-width: 619px) 100vw, 619px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-2.png"/></noscript>

让我们尝试使用排序操作并分析进一步的报告。

`>>> b.sort("Name").show()`

**截图:**

![Output 3](../Images/bdb6d4234bb4737aa9ca5be0c08864be.png)

<noscript><img class="alignnone wp-image-500502 size-full" src="../Images/bdb6d4234bb4737aa9ca5be0c08864be.png" alt="Output 3" width="263" height="175" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-3.png"/></noscript>

提供的列名相应地对数据框中的数据进行排序，然后进一步返回数据。
我们也可以有多个列来对数据进行排序，从结果来看，我们现在将尝试分析这种映射通常是如何工作的。

这里有两个名字，约翰的薪水是 25000，萨尔一栏是 15000。因此，如果我们将 sort 函数用于 Sal 列，它也会相应地对数据进行排序。

**代码:**

`>>> b.sort("Name","Sal").show()`

在这里，我们可以看到 Sal 现在也按照 Name 列进行了升序排序。

**截图:**

![Output 4](../Images/2b0f78d5f0c2cca1c400fb285b518f06.png)

<noscript><img class="alignnone wp-image-500503 size-full" src="../Images/2b0f78d5f0c2cca1c400fb285b518f06.png" alt="Output 4" width="274" height="185" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/08/PySpark-Sort-4.png"/></noscript>

默认的排序模式是 ASC，我们可以将该模式定义为 ASC 和 DESC。

让我们看看如何手动将它传递到模式上。

`>>> b.sort(col('Name').asc(),col('Sal').desc()).show()`

在这里，我们明确地将排序模式定义为 desc()和 asc()。Desc()按降序排序，Asc 按升序排序。

`>>> b.sort(col('Name').desc(),col('Sal').desc()).show()
>>> b.sort(col('Name').asc(),col('Sal').asc()).show()`

通过这种方式，可以根据用户和所需的数据模式来控制排序模式。

**截图:**

![output](../Images/35b8411cf2786cc9961d2d73439a0744.png)

<noscript><img class="alignnone size-full wp-image-500504" src="../Images/35b8411cf2786cc9961d2d73439a0744.png" alt="output" width="459" height="472" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/08/output-5.png 459w, https://cdn.educba.com/academy/wp-content/uploads/2021/08/output-5-292x300.png 292w" sizes="(max-width: 459px) 100vw, 459px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/08/output-5.png"/></noscript>

这是 PySpark 中 PySpark 排序的一些例子。

**注:**

1.  PySpark 排序是 PySpark 数据模型的一个排序函数。
2.  PySpark Sort 按升序和降序对数据进行排序，默认为升序。
3.  PySpark Sort 允许在分区上混排数据。
4.  PySpark Sort 可以占用一列，也可以占用多列。
5.  PySpark 排序不保证输出的总顺序

### 结论

从上面的文章中，我们看到了 PySpark 的排序工作。从各种例子和分类中，我们试图理解这个排序函数在 PySpark 中是如何使用的，以及在编程级别使用了什么。所使用的各种方法显示了它如何简化数据分析的模式以及同样的成本效益模型。

我们还看到了 PySpark 数据框架中 Sort 的内部工作原理和优点，以及它在各种编程目的中的使用。此外，语法和例子帮助我们更精确地理解了函数。

### 推荐文章

这是 PySpark 排序的指南。这里我们讨论一下 PySpark 排序函数的简介，语法，如何在 PySpark 中工作？和示例。您也可以看看以下文章，了解更多信息–

1.  [PySpark 收集](https://www.educba.com/pyspark-collect/)
2.  [PySpark 时间戳](https://www.educba.com/pyspark-timestamp/)
3.  [PySpark SQL 类型](https://www.educba.com/pyspark-sql-types/)
4.  [PySpark 枢轴](https://www.educba.com/pyspark-pivot/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>