# PySpark 枢轴

> 原文:[https://www.educba.com/pyspark-pivot/](https://www.educba.com/pyspark-pivot/)

![PySpark pivot](../Images/8ad0c7a803564e7708c04eda766c0a3e.png)

<noscript><img class="alignnone size-full wp-image-474493" src="../Images/8ad0c7a803564e7708c04eda766c0a3e.png" alt="PySpark pivot" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot.jpg"/></noscript>

## PySpark pivot 简介

PySpark pivot 是一个 PYSPARK PIVOT，用于将一列中的数据转置到多列中。此外，它从行转置到列。

PySpark pivot 用于将数据从一个数据框列旋转到多个列。它是一个聚合函数，用于在 PySpark 中将数据从一列旋转到多列。这提高了数据的性能，并且通常是数据分析的更便宜的方法。透视后，我们还可以使用 unpivot 函数将数据框从分析开始的地方带回来。

<small>网页开发、编程语言、软件测试&其他</small>

在本文中，我们将尝试分析 PySpark 中用于 pivot 的各种方法。

让我们试着更详细地了解一下支点。

**语法**

PIVOT 函数的语法是:-

`>>> c= b.groupBy("Name").pivot("Add").count().show()
>>> c.show()`

b:-用于列转换的数据框。

**groupBy** :-对列进行分组所需的 groupBy。

**pivot** :与列名一起使用的透视函数。

C:-新的 PySpark 数据框架。

**截图:-**

![PySpark pivot output](../Images/6862146e5246350b94b7215e05914f65.png)

<noscript><img class="alignnone size-full wp-image-474145" src="../Images/6862146e5246350b94b7215e05914f65.png" alt="PySpark pivot output" width="470" height="60" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output.png 470w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-300x38.png 300w" sizes="(max-width: 470px) 100vw, 470px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output.png"/></noscript>

### PySpark 枢轴的工作

让我们看看 PySpark 中的 PIVOT 操作是如何工作的

透视操作用于将行转置为列。该转换包括将数据从 PySpark 数据框中的一列旋转到多列。这是一个聚合操作，它将值分组并绑定在一起。

pivot 方法返回一个分组的数据对象，所以如果不在 pivot 完成后使用聚合函数，我们就不能使用 show()方法。可以使用 sum count 等聚合函数来检查透视值。

在 PySpark 2.0 之后，性能 pivot 得到了改进，因为 pivot 操作是一种开销较大的操作，需要数据组并在 PySpark 数据框中添加新列。

它接受列值，并基于新数据框中的数据分组对该值进行透视，该数据框可进一步用于数据分析。该操作涉及多个列中的列数据的转换，这进一步涉及用于使操作变得昂贵的聚合函数，并且有时还会发生内存异常。

取消透视操作是一种反向透视操作，用于将值重新分配回数据框。它再次将列旋转回行值。

让我们通过一些代码示例来检查 PIVOT 方法的创建和工作。

### PySpark pivot 示例

让我们看一些枢纽操作如何工作的例子

让我们从在 PySpark 中创建简单数据开始。

`>>> data1  = [{'Name':'Jhon','ID':21.528,'Add':'USA'},{'Name':'Joe','ID':3.69,'Add':'USA'},{'Name':'Tina','ID':2.48,'Add':'IND'},{'Name':'Jhon','ID':22.22, 'Add':'USA'},{'Name':'Joe','ID':5.33,'Add':'INA'}] A sample data is created with Name, ID and ADD as the field.
>>> a = sc.parallelize(data1)
RDD is created using sc.parallelize.
>>> b = spark.createDataFrame(a)
Created Data Frame using Spark.createDataFrame.`

**截图:-**

![PySpark pivot output 1](../Images/e1e1110f05c3b8955729dddca78ae0d7.png)

<noscript><img class="alignnone size-full wp-image-474141" src="../Images/e1e1110f05c3b8955729dddca78ae0d7.png" alt="PySpark pivot output 1" width="624" height="114" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-1.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-1-300x55.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-1-620x114.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-1.png"/></noscript>

让我们尝试使用 PySpark 数据框架的轴心。

`>>> c= b.groupBy("Name").pivot("Add").count().show()`

为了旋转数据列，我们需要基于列值聚合函数。此的返回类型将是分组数据，该数据可进一步用于计数操作，以显示为结果输出。

因此，pivot 将更改数据框的行列，并根据 PySpark 数据框中的 Name 列对数据进行分组。

**输出:-**

![PySpark pivot output 2](../Images/1048fa0fcb58bb362ebcc45d822a88a4.png)

<noscript><img class="alignnone size-full wp-image-474142" src="../Images/1048fa0fcb58bb362ebcc45d822a88a4.png" alt="PySpark pivot output 2" width="479" height="162" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-2.png 479w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-2-300x101.png 300w" sizes="(max-width: 479px) 100vw, 479px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-2.png"/></noscript>

分组元素和透视元素可以相同，并且数据可以基于同一列进行透视。

让我们用一些例子来验证这一点。

`>>> c= b.groupBy("Name").pivot("Name").count().show()`

它根据列值对数据进行分组，然后对 PySpark 数据框中的列执行透视操作。

**输出:-**

![output 3](../Images/86de7940d1670b01c62d48f5fa063988.png)

<noscript><img class="alignnone wp-image-474143 size-full" src="../Images/86de7940d1670b01c62d48f5fa063988.png" alt="output 3" width="561" height="147" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-3.png 561w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-3-300x79.png 300w" sizes="(max-width: 561px) 100vw, 561px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-3.png"/></noscript>

我们还可以使用 sum 作为聚合函数，并相应地旋转数据。

让我们尝试对 ID 求和，然后用它来透视数据。

`>>> c= b.groupBy("Add").pivot("Name").sum("ID").show()`

这将对 ID 求和，并根据相加结果在新列中赋值；不满足条件的被赋值为空。

**截图:-**

![output 4](../Images/a9f968687190ce6d1d715a0d25275c41.png)

<noscript><img class="alignnone wp-image-474144 size-full" src="../Images/a9f968687190ce6d1d715a0d25275c41.png" alt="output 4" width="498" height="143" srcset="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-4.png 498w, https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-4-300x86.png 300w" sizes="(max-width: 498px) 100vw, 498px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2021/04/PySpark-pivot-output-4.png"/></noscript>

这是 PySpark 中 PIVOT 函数的一些例子。

**注:-**

1.  透视是一种数据帧转置操作。
2.  PIVOT 用于将数据从一个数据框列旋转到多个列。
3.  PIVOT 将行分组，然后将元素转换为多列。
4.  透视是行到列的转换。
5.  PIVOT 是一种开销较大的操作，因为它将行数据转换为列数据。

### 结论

从上面的文章中，我们看到了 PySpark 中 PIVOT 操作的转换。通过各种例子和分类，我们试图理解 PySpark 数据框架的旋转是如何在 PySpark 中发生的，以及在编程级别使用了什么。

我们还看到了 PySpark 数据框架中 PIVOT 的内部工作方式和优势，以及它在各种编程目的中的使用。此外，语法和例子帮助我们更准确地理解函数。

### 推荐文章

这是 PySpark pivot 的指南。在这里，我们讨论 PySpark 数据框架中 PIVOT 的内部工作和优点，以及它在各种编程目的中的使用。您也可以看看以下文章，了解更多信息–

1.  [PySpark 聚结器](https://www.educba.com/pyspark-coalesce/)
2.  [py 帕克集团](https://www.educba.com/pyspark-groupby/)
3.  [PySpark 降序排列](https://www.educba.com/pyspark-orderby-descending/)
4.  [PySpark 当](https://www.educba.com/pyspark-when/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>