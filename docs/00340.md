# PySpark 读取 CSV

> 原文:[https://www.educba.com/pyspark-read-csv/](https://www.educba.com/pyspark-read-csv/)

![PySpark Read CSV](../Images/450974004ad64ff349ed870f47fd923d.png)

<noscript><img class="alignnone size-full wp-image-553778" src="../Images/450974004ad64ff349ed870f47fd923d.png" alt="PySpark Read CSV" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV.jpg"/></noscript>

## PySpark Read CSV 简介

Pyspark read CSV 为数据帧的阅读器提供了一个 CSV 的路径来读取 Pyspark 的数据帧中的 CSV 文件，以便保存或写入 CSV 文件。使用 PySpark read CSV，我们可以从目录中读取单个或多个 CSV 文件。PySpark 将支持通过使用空格、制表符、逗号和任何我们在 CSV 文件中使用的分隔符来读取 CSV 文件。

### 概观

apache spark 中的数据帧将被定义为一个分布式集合，我们可以认为数据是通过使用命名列来组织的。数据框相当于关系数据库中的表或 python 语言的数据框。数据框是使用各种来源在结构化数据文件中构建的。

<small>网页开发、编程语言、软件测试&其他</small>

Apache PySpark 提供了用于读取 Spark 数据帧中的 CSV 文件的 CSV 路径，以及用于写入和保存指定 CSV 文件的 spark 数据帧的对象。在读取和写入 CSV 文件中的数据帧时，pyspark CSV 中有多个选项可用。在使用 pyspark read CSV 时，我们使用分隔符选项。分隔符用于指定 CSV 文件的列的分隔符；默认情况下，pyspark 会将其指定为逗号，但我们也可以将其设置为任何其他分隔符类型。

### 如何使用 PySpark 读取 CSV 数据？

我们可以在 PySpark 中使用单个或多个 CSV 文件进行读取。我们需要遵循以下步骤来使用文件数据。首先，我们需要在我们的系统中安装 PySpark。

*   在下面的例子中，我们使用 pip 命令在系统中安装 PySpark，如下所示。

**代码:**

```
pip install pyspark 
```

![PySpark Read CSV 1](../Images/765b72428e3015c72782e2523cec47bb.png)

<noscript><img class="alignnone size-full wp-image-553261" src="../Images/765b72428e3015c72782e2523cec47bb.png" alt="PySpark Read CSV 1" width="624" height="176" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-1.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-1-300x85.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-1-620x176.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-1.png"/></noscript>

*   在安装完 pyspark 模块后，我们登录 python shell，如下所示。

**代码:**

```
python
```

![PySpark Read CSV 2](../Images/0adba75ec9e1d82ba3332224eaecf1b7.png)

<noscript><img class="alignnone size-full wp-image-553263" src="../Images/0adba75ec9e1d82ba3332224eaecf1b7.png" alt="PySpark Read CSV 2" width="624" height="80" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-2.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-2-300x38.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-2-620x80.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-2.png"/></noscript>

*   在 python shell 中登录后，我们导入所需的包，这是我们读取 CSV 文件所需要的。我们正在导入 spark 会话、管道、行和令牌化器包，如下所示。

**代码:**

```
from pyspark.ml import Pipeline
from pyspark.sql import SparkSession
from pyspark.ml.feature import Tokenizer
from pyspark.sql import Row
```

![PySpark Read CSV 3](../Images/d276fef6ba8bb5c40b9e46885875f821.png)

<noscript><img class="alignnone size-full wp-image-553265" src="../Images/d276fef6ba8bb5c40b9e46885875f821.png" alt="PySpark Read CSV 3" width="624" height="105" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-3.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-3-300x50.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-3-620x105.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-3.png"/></noscript>

*   在这一步中导入模块后，我们将变量定义为以 PY 格式读取 CSV 文件。

**代码:**

```
py = SparkSession.builder.appName ('Pyspark read csv').getOrCreate ()
```

![PySpark Read CSV 4](../Images/e4775d6efef6f789f28dabef737686fd.png)

<noscript><img class="alignnone size-full wp-image-553266" src="../Images/e4775d6efef6f789f28dabef737686fd.png" alt="PySpark Read CSV 4" width="624" height="94" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-4.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-4-300x45.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-4-620x94.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-4.png"/></noscript>

*   在这一步中定义变量后，我们将 CSV 名称作为 pyspark 加载，如下所示。

**代码:**

```
read_csv = py.read.csv('pyspark.csv')
```

![PySpark Read CSV 5](../Images/8850bc09d3d3dd17c5a86a9451d464e6.png)

<noscript><img class="alignnone size-full wp-image-553267" src="../Images/8850bc09d3d3dd17c5a86a9451d464e6.png" alt="PySpark Read CSV 5" width="624" height="60" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-5.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-5-300x29.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-5-620x60.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-5.png"/></noscript>

*   在此步骤中，CSV 文件从 CSV 文件中读取数据，如下所示。

**代码:**

```
rcsv = read_csv.toPandas()
rcsv.head()
```

![PySpark Read CSV 6](../Images/c3587edadce00962ea03714902222175.png)

<noscript><img class="alignnone size-full wp-image-553269" src="../Images/c3587edadce00962ea03714902222175.png" alt="PySpark Read CSV 6" width="624" height="109" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-6.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-6-300x52.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-6-620x109.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/PySpark-Read-CSV-6.png"/></noscript>

### Pyspark 读取多个 CSV 文件

通过使用 read CSV，我们可以在一个代码中读取单个或多个 CSV 文件。要读取多个 CSV 文件，我们需要在定义 CSV 文件的路径时给出多个文件名。在下面的例子中，我们使用了如下两个文件。

**代码:**

```
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.sql import SparkSession
spark_csv = SparkSession.builder.appName('Pyspark read multiple csv').getOrCreate()
path_csv = ['authors.csv',  'authors.csv']
file_csv = spark_csv.read.csv()
df_csv = file_csv.toPandas()
df_csv.head()
df_csv.tail()
```

![Pyspark read Multiple CSV Files](../Images/d28a12b84f9299a7d97a80fda051ca10.png)

<noscript><img class="alignnone size-full wp-image-553271" src="../Images/d28a12b84f9299a7d97a80fda051ca10.png" alt="Pyspark read Multiple CSV Files" width="624" height="257" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Pyspark-read-Multiple-CSV-Files.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Pyspark-read-Multiple-CSV-Files-300x124.png 300w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Pyspark-read-Multiple-CSV-Files.png"/></noscript>

在下面的例子中，我们用一段代码读取三个文件，如下所示。我们使用如下三个不同的文件。

**代码:**

```
from pyspark.sql import SparkSession
from pyspark.ml import Pipeline
from pyspark.sql import SparkSession
spark_csv = SparkSession.builder.appName('Pyspark read multiple csv').getOrCreate()
path_csv = [spark1.csv',  spark2.csv', 'spark3.csv']
file_csv = spark_csv.read.csv()
df_csv = file_csv.toPandas()
df_csv.head()
df_csv.tail()
```

![reading three files](../Images/c0ca552482776545a3d9d8b393971840.png)

<noscript><img class="alignnone wp-image-553273 size-full" src="../Images/c0ca552482776545a3d9d8b393971840.png" alt="reading three files" width="624" height="283" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Using-three-different-files.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Using-three-different-files-300x136.png 300w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Using-three-different-files.png"/></noscript>

### Pyspark 阅读多种习俗

在创建数据框时，通过使用 pyspark，我们可以使用 struct 类型和类名作为 struct 字段来指定自定义结构。结构类型是用于定义列名的结构字段的集合。下面的例子显示 pyspark 读取多个海关如下。

**代码:**

```
import pyspark
from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType
custom_spark = SparkSession.builder.master ("local[1]") \
.appName ('SparkByExamples.com') \ .getOrCreate()
student = [("AB", "", "CD", 25),  ("PQ", "QR", "", 15),  ("XY", "", "YZ", 35) ]
stud_schema = StructType ([ \
StructField ("stud_fname", StringType (), True), \
StructField ("stud_mname", StringType (), True), \
StructField ("stud_lname", StringType (), True), \
StructField ("stud_id", IntegerType (), True) \ ])
stud = custom_spark.createDataFrame (data = student, schema = stud_schema)
stud.printSchema()
```

![Multiple customs](../Images/8b9060616dd0109d9592d42f7768b6e8.png)

<noscript><img class="alignnone size-full wp-image-553274" src="../Images/8b9060616dd0109d9592d42f7768b6e8.png" alt="Multiple customs" width="624" height="299" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Multiple-customs.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Multiple-customs-300x144.png 300w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Multiple-customs.png"/></noscript>

### Pyspark 读取目录

我们也可以从指定的目录中读取所有的 CSV 文件。为了从指定目录中读取所有 CSV 文件，我们使用“*”符号。在下面的例子中，我们在目录中保存了两个文件，如下所示。

**代码:**

```
from pyspark.sql import SparkSession
spark_csv = SparkSession.builder.appName ('Read all').getOrCreate()
all_csv = spark_csv.read.csv()
read_all = all_csv.toPandas()
read_all.head()
read_all.tail()
```

![Read Directory](../Images/1a4a9eadc802b5828c9aa4ab0fa4fbee.png)

<noscript><img class="alignnone size-full wp-image-553275" src="../Images/1a4a9eadc802b5828c9aa4ab0fa4fbee.png" alt="Read Directory" width="624" height="120" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Read-Directory.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Read-Directory-300x58.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Read-Directory-620x120.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Read-Directory.png"/></noscript>

以下示例显示了 PySpark 读取目录。我们将三个文件放在一个指定的目录中，如下所示。

**代码:**

```
from pyspark.sql import SparkSession
spark_csv = SparkSession.builder.appName ('Read all').getOrCreate()
all_csv = spark_csv.read.csv()
read_all = all_csv.toPandas()
read_all.head()
read_all.tail()
read_all.head()
```

![Specified directory](../Images/ecca3aaacf66d454b5a77539c135d795.png)

<noscript><img class="alignnone size-full wp-image-553276" src="../Images/ecca3aaacf66d454b5a77539c135d795.png" alt="Specified directory" width="639" height="148" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Specified-directory.png 639w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Specified-directory-300x69.png 300w" sizes="(max-width: 639px) 100vw, 639px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Specified-directory.png"/></noscript>

### 例子

以下是不同的例子:

#### 示例#1

在本例中，我们使用一个 CSV 文件。

**代码:**

```
from pyspark.sql import SparkSession
single = SparkSession.builder.appName('Pyspark read csv').getOrCreate()
single_csv = single.read.csv()
rcsv = single_csv.toPandas()
rcsv.head()
```

![Example 1](../Images/2a7f65813dd2cbf1d616a33f4369eed3.png)

<noscript><img class="alignnone size-full wp-image-553277" src="../Images/2a7f65813dd2cbf1d616a33f4369eed3.png" alt="Example 1" width="624" height="155" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-1.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-1-300x75.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-1-620x155.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-1.png"/></noscript>

#### 实施例 2

以下示例显示 PySpark 火花读取 CSV 如下。我们使用两个 CSV 文件。

**代码:**

```
from pyspark.sql import SparkSession
two_csv = SparkSession.builder.appName ()
path_two = ['spark1.csv', 'spark2.csv']
file_two = two_csv.read.csv (path_two, sep=',')
df_two = file_two.toPandas()
df_two.head()
df_two.tail()
```

![Example 2](../Images/7b076142a9c95d33d0dade74e5343f66.png)

<noscript><img class="alignnone size-full wp-image-553278" src="../Images/7b076142a9c95d33d0dade74e5343f66.png" alt="Example 2" width="624" height="218" srcset="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-2.png 624w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-2-300x105.png 300w, https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-2-620x218.png 620w" sizes="(max-width: 624px) 100vw, 624px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2022/09/Example-2.png"/></noscript>

### 关键要点

*   我们在使用 PySpark 读取 CSV 文件时使用了多个选项。推断架构选项告诉读者从源文件推断数据类型。
*   我们可以在单个或多个文件上使用它，也可以读取所有的 CSV 文件。

### 常见问题解答

下面是提到的常见问题:

#### Q1。为什么我们使用 PySpark read CSV？

**答:**基本上它的用途就是读取指定的 CSV 文件。通过使用 spark，我们可以读取单个或多个 CSV 文件，也可以读取所有 CSV 文件。

#### Q2。PySpark read CSV 中的分隔符有什么用？

**答:**该选项用于指定 CSV 文件中某一列的分隔符，默认为逗号。

#### Q3。PySpark 中的 header 参数有什么用？

**答:**header 参数用于读取我们在代码中定义的文件的第一行。

### 结论

在读取和写入 CSV 文件中的数据帧时，PySpark CSV 中有多个选项可用。Pyspark 读取 CSV，提供一个 CSV 的路径给数据帧的阅读器来读取 PySpark 的数据帧中的 CSV 文件，用于保存或写入 CSV 文件。

### 推荐文章

这是 PySpark 读取 CSV 的指南。在这里，我们讨论了简介以及如何使用 PySpark 读取 CSV 数据，并给出了不同的示例。您也可以看看以下文章，了解更多信息–

1.  [PySpark 写 CSV](https://www.educba.com/pyspark-write-csv/)
2.  [PySpark MLlib](https://www.educba.com/pyspark-mllib/)
3.  [PySpark 数据帧](https://www.educba.com/pyspark-dataframe/)
4.  PySpark fillna

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>