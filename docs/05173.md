# R 中的逻辑回归

> 原文:[https://www.educba.com/logistic-regression-in-r/](https://www.educba.com/logistic-regression-in-r/)

![Logistic Regression in R](../Images/e3c79290f2eb78234be072090da3efe8.png)

<noscript><img class="alignnone size-full wp-image-200907" src="../Images/e3c79290f2eb78234be072090da3efe8.png" alt="Logistic Regression in R" width="900" height="500" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2019/08/Logistic-Regression-in-R.png"/></noscript>

## R 中的逻辑回归介绍

R 中的 Logistic 回归被定义为统计计量领域中的二元分类问题。通过估计概率的不同发生率，在逻辑函数的指导下，因变量和自变量之间的差异，即，它用于预测自变量的结果(1 或 0，是/否)，因为它是用于预测连续输出变量的线性回归的延伸。

### R 中的 Logistic 回归是如何工作的？

逻辑回归是统计领域中使用的一种技术，通过估计概率的不同出现，在逻辑函数的指导下测量因变量和自变量之间的差异。它们可以是二项式的(有或没有结果)，也可以是多项式的(一般与差非常差)。概率值介于 0 和 1 之间，变量应为正数(< 1)。

<small>Hadoop、数据科学、统计学&其他</small>

它以因变量为目标，遵循以下步骤:

*   n-对采集的数据集进行固定试验的次数。
*   两种结果试验。
*   概率的结果应该是相互独立的。
*   每次试验成功和失败的概率必须相同。

在这方面，我们以 ISLR 包为例，它为训练提供了各种数据集。为了拟合模型，这里使用了广义线性模型函数(glm)。为了建立逻辑回归，glm 函数是优选的，并且使用用于分析任务的摘要来获得它们的细节。

**工作步骤:**

逻辑回归的工作步骤遵循某些术语元素，如:

*   对进行概率估计的概率建模
*   预言；预测；预告
*   初始化阈值(高或低特异性)
*   混淆矩阵
*   曲线下的绘图区域(AUC)

### 逻辑回归在 R 中的实现实例

下面是 R 中逻辑回归的一些例子:

*   **数据加载:**安装 ISLR 包。
*   **要求(ISLR)**
*   **加载所需的包:** ISLR

对于本文，我们将使用 RStudio 中的数据集“Weekly”。数据集暗示了从 1990 年到 2010 年每周股票的汇总细节。

*   **要求(ISLR)**
*   **姓名(OJ)**

**输出:**

[1] “Purchase”   “WeekofPurchase”, “StoreID”, “PriceCH” [5] “PriceMM”       “DiscCH”         “DiscMM”         “SpecialCH” [9] “SpecialMM”   “LoyalCH”      “SalePriceMM”    “SalePriceCH” [13] “PriceDiff”      “Store7”         “PctDiscMM”      “PctDiscCH”[17] ” ListPriceDiff”  “STORE”

**str(OJ)**

**显示 18 个变量的 1070 个观测值。**

![ISLR pacakage](../Images/51e2855e5dd20b6946495da68a6803c5.png)

<noscript><img class="alignnone size-full wp-image-200180" src="../Images/51e2855e5dd20b6946495da68a6803c5.png" alt="ISLR pacakage" width="591" height="311" srcset="https://cdn.educba.com/academy/wp-content/uploads/2019/08/ISLR-pacakage.png 591w, https://cdn.educba.com/academy/wp-content/uploads/2019/08/ISLR-pacakage-300x158.png 300w" sizes="(max-width: 591px) 100vw, 591px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2019/08/ISLR-pacakage.png"/></noscript>

我们的数据集有 1070 个观察值和 18 个不同的变量。这里我们有特殊的 MM，特殊的 CH 有依赖的结果。我们就拿一个特殊的 MM 属性来说吧，观察正确，准确率 84 %。

**表格(OJ$SpecialMM)**

0  1

897 173

接下来，求概率

**897/1070**

[1] 0.8383178

在下一步中，为了获得更好的样本，将数据集分成训练和测试数据集是很好的做法

*   图书馆(caTools)
*   set.seed(88)
*   split = sample . split(OJ $ special mm，SplitRatio = 0.84)

![splitting sample](../Images/4f231bab038fb35010be9fc0d92111fb.png)

<noscript><img class="alignnone size-full wp-image-200176" src="../Images/4f231bab038fb35010be9fc0d92111fb.png" alt="splitting sample" width="446" height="469" srcset="https://cdn.educba.com/academy/wp-content/uploads/2019/08/splitting-sample-1.png 446w, https://cdn.educba.com/academy/wp-content/uploads/2019/08/splitting-sample-1-285x300.png 285w" sizes="(max-width: 446px) 100vw, 446px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2019/08/splitting-sample-1.png"/></noscript>

考虑到 qt 有训练集，qs 有测试集样本数据。

*   qt =子集(OJ，split = =真)
*   qs =子集(OJ，split==FALSE)

**nrow(qt)**

[1] 898

**nrow(qs)**

[1] 172

因此，我们有 898 个训练集和 172 个测试样本。

接下来使用 Summary()给出回归分析的偏差和系数表的细节。

*   quality log = glm(special mm ~ saleprice mm+WeekofPurchase，data=qt，family=binomial)
*   总结(质量日志)

**输出:**

| Call:glm(formula = special mm ~ saleprice mm+WeekofPurchase，family = binomial，data = qt)偏差残差:最小 1Q 中值最大 3Q-1.2790  -0.4182  -0.3687  -0.2640  2.4284系数:估计标准。误差 z 值 Pr(>&#124;z&#124;)(截距)2.910774 1.616328 1.801 0.07173。salepricemm-4.5388464 0.405808-11.184 < 2e-16 * * *采购周 0.015546 0.005831 2.666 0.00767 **—零偏差:897 个自由度上的 794.01

剩余偏差:895 个自由度上的 636.13

AIC: 642.13

费希尔评分迭代次数:5 次

 |

根据上述分析，可以说系数表为 WeekofPurchase 提供了正值，并且它们至少有两个星号，这意味着它们是模型的重要代码。

#### 示例 1–预测技术

这里我们将使用 R 包中的预测训练函数并提供概率；我们使用一个名为 type=response 的参数。首先，让我们看看应用于训练集(qt)的预测。R 以 P(y=1|X)的形式预测结果，边界概率为 0.5。

**predict train = predict(quality log，type="response")**

中值、平均值和最小值、最大值的汇总结果。

**摘要(predictTrain)执行给出**

量滴第一曲。中值平均第三区最大值

0.02192 0.03342 0.07799 0.16147 0.25395 0.89038

**tapped(预测训练，Qt $ special)**

![prediction technique](../Images/e2362a52bc7a83be138d4b25267cfb9d.png)

<noscript><img class="alignnone size-full wp-image-200159" src="../Images/e2362a52bc7a83be138d4b25267cfb9d.png" alt="prediction technique" width="496" height="469" srcset="https://cdn.educba.com/academy/wp-content/uploads/2019/08/prediction-technique.png 496w, https://cdn.educba.com/academy/wp-content/uploads/2019/08/prediction-technique-300x284.png 300w" sizes="(max-width: 496px) 100vw, 496px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2019/08/prediction-technique.png"/></noscript>

为了计算真实概率的平均值，使用了 tapply()函数。

**tapply(predictTrain，qt$SpecialMM，mean)**

0        1

0.1224444 0.3641334

因此，我们在上面的陈述中发现，真特殊的可能性 MM 意味着值是 0.34，而对于真差值是 0.12。

#### 示例 2–计算阈值

如果 P > T——预测较差，特别是 MM

如果 P < T-预测是好的

**分类矩阵:**

表(qt$SpecialMM，predictTrain >0.5)

假真

0  746   7

1   105   40

**计算灵敏度和特异性**

40/145

[1] 0.2758621

746/753

[1] 0.9907039

**测试集预测**

predictTest = predict(QualityLog，type = "response "，newdata = qs)

表(qs$SpecialMM，预测测试> = 0.3)

假真

0   130 14

1     10  18

表(qs$SpecialMM，预测测试> = 0.5)

假真

0   140   4

1    18    10

**计算精度**

150/172

[1] 0.872093

共有 172 例，其中 144 例为好，28 例为差。

**绘制 ROC 曲线:**这是绘制性能测量 ROC 曲线的最后一步。好的 AUC 值应该接近 1，而不是 0.5。使用概率 0.5、0.7、0.2 进行检查，以预测阈值如何增加和减少。这是通过在 ROC 曲线中同时绘制阈值来完成的。考虑到更高的灵敏度，选择 pick 是个不错的选择。

### 逻辑回归技术

让我们看一个使用 R 的逻辑实现，因为它使模型的拟合变得非常容易。

有两种类型的技术:

*   多项式逻辑回归
*   有序逻辑回归

前者适用于响应变量多于或等于两个类别的情况。当订单很大时，后期工作。

### 结论

因此，我们已经了解了回归背后的基本逻辑，并对 r 的特定数据集实施了逻辑回归。二项式或二元回归测量二元响应和预测变量的分类值。他们在分析中起着至关重要的作用，行业专家希望了解线性和逻辑回归。他们有自己的挑战，在实际示例中，我们已经完成了数据清理和预处理步骤。总的来说，我们已经看到了逻辑回归是如何以简单易行的方式解决分类结果的问题的。

### 推荐文章

这是 r 中逻辑回归的指南。在这里，我们讨论 r 中逻辑回归使用的不同方法的工作原理、不同技术和广泛解释。您也可以查看以下文章以了解更多信息——

1.  [机器学习框架](https://www.educba.com/machine-learning-frameworks/)
2.  [R vs Python](https://www.educba.com/r-vs-python/)
3.  [Python 字符串函数](https://www.educba.com/python-string-functions/)
4.  [Python 是脚本语言吗](https://www.educba.com/python-scripting-language/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>