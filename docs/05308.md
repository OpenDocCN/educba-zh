# 火花广播

> 原文:[https://www.educba.com/spark-broadcast/](https://www.educba.com/spark-broadcast/)

![Spark Broadcast](../Images/20d1124004b4bc3fda19de8cdaf78b30.png)

<noscript><img class="alignnone size-full wp-image-350154" src="../Images/20d1124004b4bc3fda19de8cdaf78b30.png" alt="Spark Broadcast" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast-1.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast-1-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast-1-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast-1.jpg"/></noscript>

## 火花广播简介

Apache Spark 使用共享变量。当驱动程序向集群执行器发送任务时，集群的每个节点都会收到共享变量的副本。Apache Spark 支持两种基本类型的共享变量——累加器和广播。Apache Spark 应用广泛，是一个开源的集群计算框架。这带来了计算机器学习、API 流和图形处理算法等功能。广播变量通常在几个阶段使用，需要相同的数据。SparkContext.broadcast(v)被调用，其中变量 v 被用于创建广播变量。

### 句法

上面的代码分享了 PySpark 类广播的细节。

<small>Hadoop、数据科学、统计学&其他</small>

`class pyspark.Broadcast (
sc = None,
value = None,
pickle_registry = None,
path = None
)`

**解释:**广播的变量用于保存跨所有节点的庞大数据集的副本。缓存在所有计算机上的是此变量，不会在计算机上发送任务。

### 为什么使用 Spark 广播？

当需要在执行器中缓存巨大的数据集时，使用广播变量。让我们想象一下，我们需要查找 pin 码或邮政编码来进行转换，在这种情况下，我们既不能每次都查询庞大的数据库，也不能每次都将庞大的表查找发送给执行者。唯一的解决方案是将表查找转换成一个广播变量，并由 Spark 缓存在每个执行器中以供将来使用。

**Note:** Once the values of nodes are broadcasted, the value should not be changed by us again. We make sure that every node has an exact copy of the same data. The value which is modified is sent to a different node which would give results of expectancy.

### 星火广播是如何工作的？

broadcast 变量允许 Spark 的开发人员在不同的节点上保存一个安全的只读缓存变量。与所需的任务，只有航运副本而已。无需浪费大量时间和传输网络输入和输出，它们可用于为节点提供输入数据集的大量副本。Spark 可以使用各种广播算法来分发广播变量，这可能会大大降低通信成本。

执行 Spark 的操作有不同的阶段。然后通过操作——洗牌来分离这些阶段。在每个阶段，Spark 自动广播需要在缓存中的公共数据，并且应该序列化，在每个任务运行之前，每个节点将再次从缓存中反序列化。因此，如果广播的变量是显式创建的，则需要使用相同的数据执行多个分阶段的任务，应该执行上述操作。上面提到的通过包装函数 SparkConext.broadcast 创建的广播变量

**代码:**

`val broadcastVar = sc.broadcast(Array(1, 2, 3))
broadcastVar: org.apache.spark.broadcast.Broadcast[Array[Int]] = Broadcast(0)
broadcastVar.value
res2: Array[Int] = Array(1, 2, 3)
package org.spark.broacast.crowd.now.aggregator.sample2
import org.apache.spark.broadcast.Broadcast
import org.apache.spark.rdd.RDD
import org.hammerlab.coverage.histogram.JointHistogram.Depth
trait CanDownSampleRDD[V] {
def rdd: RDD[((Depth, Depth), V)] def filtersBroadcast: Broadcast[(Set[Depth], Set[Depth])] @transient lazy val filtered = filterDistribution(filtersBroadcast)
(for {
((d1, d2), value) ? rdd
(d1Filter, d2Filter) = filtersBroadcast.value
if d1Filter(d1) && d2Filter(d2)
} yield
(d1, d2) ? value
)
.collect
.sortBy(_._1)
}`

广播的变量称为 value，它存储用户数据。该变量也返回值 broadcast。
从 py spark 导入 SparkContext

`sc = SparkContext("local", "Broadcast app")
words_new = sc.broadcast(["scala", "java", "hadoop", "spark", "akka"])
data = words_new.value
print "Stored data -> %s" % (data)
elem = words_new.value[2] print "A particular element is being printed"`

广播命令行如下所示:

`$SPARK_HOME/bin/spark-submit broadcast.py`

**输出:**

![Spark Broadcast1](../Images/ba51728fb3bf49c0dbaa0e585d2cceb8.png)

<noscript><img class="alignnone wp-image-348990 size-full" src="../Images/ba51728fb3bf49c0dbaa0e585d2cceb8.png" alt="Spark Broadcast1" width="603" height="228" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast1.jpg 603w, https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast1-300x113.jpg 300w" sizes="(max-width: 603px) 100vw, 603px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/04/Spark-Broadcast1.jpg"/></noscript>

### Spark 广播的优点和用途

下面提到了优点和用途:

*   内存访问非常直接。
*   垃圾值在处理开销中收集得最少。
*   内存格式是一个紧凑的列。
*   查询催化剂优化。
*   代码生成是整个阶段。
*   与数据框相比，按数据集编译切片类型的优势。

### 结论

我们已经看到了星火广播的概念。Spark 使用共享变量，用于处理和并行。对于信息聚合、通信关联和操作，使用累加器变量。在 map-reduce 中，为了对计数器或运算求和，我们可以使用累加器。而在 spark 中，变量是可变的。

### 推荐文章

这是星火广播的指南。这里我们讨论一下 Spark 广播的介绍，语法，为什么使用它，它是如何工作的，优点。您也可以浏览我们的其他相关文章，了解更多信息——

1.  [火花版本](https://www.educba.com/spark-versions/)
2.  [火花命令](https://www.educba.com/spark-commands/)
3.  [PySpark SQL](https://www.educba.com/pyspark-sql/)
4.  [火花阶段](https://www.educba.com/spark-stages/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>