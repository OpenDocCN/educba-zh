# 受限玻尔兹曼机

> 原文：<https://www.educba.com/restricted-boltzmann-machine/>

![Restricted Boltzmann Machine](img/90620f5d254cf237f6c4bc212a0d2aac.png)



## 受限玻尔兹曼机简介

受限玻尔兹曼机是一种通过重构我们的输入来自动发现数据中模式的方法。杰夫·辛顿是深度学习的创始人。RBM 是一个表面的两层网络，第一层是可见的，第二层是隐藏的。可见层中的每个节点都连接到隐藏层中的每个节点。受限玻尔兹曼机被认为是受限的，因为同一层的两层不连接。RBM 在数字上相当于双向翻译器。在前向路径中，RBM 接收输入并将其转换成一组对输入进行编码的数字。在反向路径中，它将此作为结果，处理这组输入，并将其反向转换以形成回扫输入。一个训练有素的网络将能够以很高的准确性执行这种反向转换。在这两步中，权重和价值观有着非常重要的作用。它们允许 RBM 解码输入之间的相互关系，并帮助 RBM 决定哪些输入值对检测正确的输出最重要。

### 受限玻尔兹曼机的工作

每个可见节点都从数据集中的一个节点接收一个低级值。在不可见层的第一个节点，X 由权重的乘积形成，并加到偏差上。这个过程的结果被馈送到激活，该激活产生给定输入信号或节点输出的功率。

<small>Hadoop、数据科学、统计学&其他</small>

![ Restricted Boltzmann machine](img/c3fb12eb27ff7af00d8af4daeba6a77a.png)



在下一个过程中，几个输入将在单个隐藏节点处连接。单个权重组合每个 X，乘积的相加组合成值，结果再次通过激活传递，给出节点的输出。每个输入 X 由单独的权重 w 组合而成。输入 X 在每个不可见节点处有三个权重，总共十二个。在层之间形成的权重成为一个数组，其中行精确到输入节点，列满足输出节点。

![ Restricted Boltzmann machine](img/ceaed12ecab53759d9099ff0a7eeda97.png)



每个不可见节点得到四个乘以权重的响应。这种效果的增加再次被加到该值上。这充当了某种激活过程发生的催化剂，并且结果再次被馈送到激活算法，该算法为每一个不可见的输入产生每一个输出。

![ Restricted Boltzmann machine](img/e6347f14fcc2b2465005af47aaaefee7.png)



这里导出的第一个模型是基于能量的模型。这个模型将标量能量与变量的每一种构型联系起来。该模型通过如下能量函数定义概率分布，

(1) ![energy function](img/b6c255dcdf6bdbe4638cbe23992563b0.png)



这里 Z 是归一化因子。这是物理系统的配分函数。

![normalizing factor](img/379424c0c026dc261399f6aae89d4cb9.png)



在这个基于能量的函数中，遵循逻辑回归，第一步将定义对数。可能性，下一个将损失函数定义为负的可能性。

![Restricted Boltzmann machine](img/ca25e19315c0cc89ace8a6cdd4a08af7.png)



使用随机梯度，![ stochastic gradient,](img/719b176b3a626d44d54f2d2f9613b319.png)



      where ![ stochastic gradient,](img/5d902ca3acab7e271ef1f74d52e8ee14.png)



  are the parameters,

具有隐藏单元的基于能量的模型被定义为“h”

观察到的部分表示为“x”

根据等式(1)，自由能 F(x)的等式定义如下

(2) ![ Restricted Boltzmann machine](img/dbf11e13440d55811a213417c5e6969f.png)



(3) ![Energy-based function](img/6cfcb7cde012aa9925f3598e6a6346a3.png)



![ Restricted Boltzmann machine](img/f8162b81e8af56e7cb5b79573ffd8046.png)



负梯度具有以下形式，

(4) ![ Restricted Boltzmann machine](img/e01b3834c053f3c4a3758467286b89ee.png)



上面的等式有两种形式，正的和负的形式。等式的符号不代表正负两项。它们显示了概率密度的影响。第一部分显示减少相应自由能的概率。第二部分显示生成样本的减少的概率。那么梯度确定如下，

(5) ![Restricted Boltzmann machine](img/cba38356725fb2ba7497c1b654aacb68.png)



这里 N 是负粒子。在这种基于能量的模型中，很难解析地识别梯度，因为它包括![negative particles](img/369ee4d68531fe06eddcc1d75ae222dc.png)的计算



因此，在这个 EBM 模型中，我们有一个不能精确描述数据的线性观察。所以在下一个模型，受限玻尔兹曼机中，隐藏层更有可能具有高精度，防止数据丢失。RBM 能量函数被定义为，

(6) ![negative particles](img/cf7214e5869fef6827586baa173aa8e8.png)



这里，W 是连接可见层和隐藏层的权重。b 是可见层的偏移量。c 是隐藏层的偏移量。通过转化为自由能，

![machine](img/f59be50e7bb1430ece225956088926be.png)



在 RBM，可见层和隐藏层的单位是完全独立的，可以写成这样:

![Restricted Boltzmann machine](img/0b8fe7a4c958547c64ec595da91b1cd8.png)



根据等式 6 和 2，神经元激活函数概率版本，

(7) ![neuron activation function,](img/00d3fb9d884ac5632d246479bfa0081f.png)



(8) ![neuron activation function,](img/afe2729fb6a4676adc41b4f6ecd66dba.png)



它被进一步简化为

(9) ![neuron activation function,](img/14f203e0280eb9e9bd9451605c49482d.png)



结合等式 5 和 9，

(10) ![Restricted Boltzmann machine](img/f5867826341927604937f403eb98622d.png)



### 受限玻尔兹曼机中的采样

N 个随机变量联合的吉布斯采样![random variables  ](img/72e853cd6014de71bf98ebce2f988592.png)



 is done through a sequence of N sampling sub-steps of the form![sub-steps](img/e96b5af74fbfb013d67ccc0b25900e6b.png)



  where

![sub-steps](img/c217e0eb694c1ef5a3e00d666570dfe1.png)



包含![random variables](img/da15243ce5baba3a687882f9f5423b15.png)



 the other random variables in ![random variables](img/576fccc62c9d70c42f9594ef745cda7e.png)



 excluding.![random variables](img/6e214b2a5d81b6174f69bc42dadd765f.png)



在 RBM，S 是一组可见和隐藏的单位。这两个部分是独立的，可以执行或阻止吉布斯采样。在这里，可见单元执行采样并给隐藏单元提供固定值，同时隐藏单元通过采样给可见单元提供固定值

![Restricted Boltzmann machine](img/c217e0eb694c1ef5a3e00d666570dfe1.png)



在这里，![hidden units](img/8a76d95cd59c7b236d37d1ded16bc2a8.png)



 is set of all hidden units. ![hidden units](img/8a76d95cd59c7b236d37d1ded16bc2a8.png)



An example  ![R25](img/d5d58bde4f7374216fc45272f98d4405.png)



 is randomly chosen to be 1 (versus 0) with probability, ![ fixed values](img/9a073d5c1454f727ebb49b9232d95096.png)



and similarly,  ![ fixed values](img/4d99c6772944f4581ec693e2e5f73400.png)



 is randomly chosen to be 1 (versus 0) with probability ![ fixed values](img/66c2fce9c557c774afcc6f871c13b208.png)



#### 对比分歧

它被用作加速采样过程的催化剂
因为我们期望为真，所以我们期望![R30](img/698dffb46d9041d1a61018773a65a870.png)



the distribution value to be close to P so that it forms a convergence to the final distribution of P

但是对比分歧并不等待连锁收敛。只有在吉布过程之后才能得到一个样本，所以我们在这里设置 k = 1，在这里它工作得非常好。

#### 持续的对比分歧

这是近似抽样形式的另一种方法。它是每种采样方法的持久状态；它通过简单地改变 k 的参数来提取新的样本

### 限制玻尔兹曼机的层数

受限玻尔兹曼机器有两层，浅层神经网络结合起来形成一个深层信念网络块。第一层是可见层，另一层是隐藏层。每个单元指的是一个类似神经元的圆圈，称为节点。隐藏层中的节点连接到可见层中的节点。但是同一层的两个节点不相连。这里，术语“受限”是指没有层内通信。每个节点处理输入，并随机决定是否传输输入。

**例题**

RBM 的重要作用是概率分布。语言的字母和声音都是独一无二的。字母的概率分布可能高也可能低。在英语中，字母 T、E 和 A 被广泛使用。但是在冰岛语中，常见的字母是 A 和 n。我们不能试图用基于英语的权重来重构冰岛语。会导致发散。

下一个例子是图像。它们的像素值的概率分布对于每种图像都不同。我们可以考虑大象和狗这两个形象；对于两个输入节点，RBM 的正向传递会产生这样的问题，我应该为大象节点还是狗节点生成一个强像素节点？。然后向后传递会产生像大象这样的问题，我应该如何期望像素的分布？通过节点产生的联合概率和激活，它们将构建一个联合共现的网络，就像大耳朵、灰色非线性管、松软的耳朵和皱纹是大象一样。因此 RBM 是深度学习和视觉化的过程；它们形成两种主要的偏向，并作用于它们的激活和重建意识。

### 受限玻尔兹曼机的优势

*   受限玻尔兹曼机是一种用于分类、回归、主题建模、协同过滤和特征学习的应用算法。
*   受限玻尔兹曼机器用于神经成像、矿山规划中的稀疏图像重建和雷达目标识别。
*   RBM 能够通过 SMOTE 程序解决不平衡数据问题
*   RBM 通过吉布抽样寻找缺失值，用于覆盖未知值
*   RBM 通过未校正的标签数据及其重建误差克服了噪声标签的问题
*   非结构化数据的问题通过将原始数据转换成隐藏单元的特征提取器来纠正。

### 结论

深度学习很厉害，是解决复杂问题的艺术；它仍然有改进的空间和实现的复杂性。自由变量必须小心配置。神经网络背后的想法[在更早的时候很难，但今天深度学习是机器学习和人工智能的脚。因此，RBM 展示了巨大的](https://www.educba.com/what-is-neural-networks/)[深度学习算法](https://www.educba.com/deep-learning-algorithms/)。它处理组合的基本单元，逐渐发展成许多流行的架构，并在许多大型行业中广泛使用。

### 推荐文章

这是受限玻尔兹曼机的指南。在这里，我们讨论它的工作，采样，优势，并限制玻尔兹曼机层。您也可以浏览我们推荐的其他文章，了解更多信息 _

1.  [机器学习算法](https://www.educba.com/machine-learning-algorithms/)
2.  [机器学习的类型](https://www.educba.com/types-of-machine-learning/)
3.  [机器学习工具](https://www.educba.com/machine-learning-tools/)
4.  [神经网络的实现](https://www.educba.com/implementation-of-neural-networks/)





