# 决策树算法

> 原文：<https://www.educba.com/decision-tree-algorithm/>

![Decision Tree Algorithm](img/549f0280fcc0cabad87daecdf6bd9219.png)



## 决策树算法简介

决策树算法是用于分类的流行的监督型机器学习算法之一。该算法基于具有条件或规则的树结构来生成作为优化结果的结果。决策树算法与三个主要部分相关联，即决策节点、设计链接和决策叶。它与分裂、修剪和树选择过程一起操作。它支持数字和分类数据来构建决策树。决策树算法对于大数据集是有效的，并且时间复杂度较低。这种算法主要用于商业中的客户细分和营销策略实施。

### 什么是决策树算法？

决策树算法是一种受监督的机器学习算法，其中数据根据某些规则在每一行被连续划分，直到生成最终结果。让我们举个例子，假设你开了一家购物中心，当然，你会希望它随着时间的推移而发展壮大。因此，你需要回头客加上你商场的新顾客。为此，你要准备不同的业务和[营销策略](https://www.educba.com/marketing-strategies-in-business/)，比如给潜在客户发送电子邮件，创造优惠和交易，瞄准新客户等。但是我们怎么知道谁是潜在客户呢？换句话说，我们如何对客户进行分类？比如，有些客户一周拜访一次，有些客户一个月拜访一次或两次，有些客户一个季度拜访一次。因此，决策树就是这样一种[分类算法](https://www.educba.com/algorithm-in-programming/)，它会将结果分类成组，直到不再有相似之处。

<small>Hadoop、数据科学、统计学&其他</small>

这样，决策树以树形结构的格式向下。

决策树的主要组件包括:

*   决策节点，也就是数据被拆分的地方，或者说，它是属性的位置。
*   决策链接，它代表一个规则。
*   决策离开，这是最终的结果。

![is a person fit](img/d924dc721332934bf424bd8b2725cd53.png)



### 决策树算法的工作原理

决策树的工作包括许多步骤:

**1。拆分**–这是将数据划分为子集的过程。可以根据如下所示的各种因素进行划分，即根据性别、身高或阶级。

![splitting](img/b1c3613d4d15a7559a705a869d3f5d47.png)



**2。修剪**——这是缩短决策树的[分支的过程，因此限制了树的深度。](https://www.educba.com/create-decision-tree/)

![tree pruning Exam](img/0ab2160a07047a245799fc18f42ffeaf.png)



修剪也有两种类型:

*   **预修剪**–在这里，当我们在任何特定的节点上没有发现属性和类之间的任何统计上的显著关联时，我们停止生长树。
*   **后期剪枝**–为了后期剪枝，我们必须验证测试集模型的性能，然后从训练集中删除过度拟合噪声导致的分支。

**3。树选择**–第三步是寻找符合数据的最小树的过程。

### 构建决策树的示例和说明

假设你想在某个特定的日子(例如星期六)打板球。决定这出戏是否会上演的因素有哪些？

显然，主要因素是气候；没有任何其他因素有这么大的可能性，因为气候有这么多的发挥中断。

我们收集了过去 10 天的数据，如下所示:

| **日** | **天气** | **温度** | **湿度** | **风** | **玩？** |
| One | 多云的 | 热的 | 高的 | 无力的 | 是 |
| Two | 快活的 | 热的 | 高的 | 无力的 | 不 |
| Three | 快活的 | 温和的 | 常态 | 强烈的 | 是 |
| Four | 下雨的 | 温和的 | 高的 | 强烈的 | 不 |
| Five | 多云的 | 温和的 | 高的 | 强烈的 | 是 |
| Six | 下雨的 | 凉爽的 | 常态 | 强烈的 | 不 |
| Seven | 下雨的 | 温和的 | 高的 | 无力的 | 是 |
| Eight | 快活的 | 热的 | 高的 | 强烈的 | 不 |
| Nine | 多云的 | 热的 | 常态 | 无力的 | 是 |
| Ten | 下雨的 | 温和的 | 高的 | 强烈的 | 不 |

现在让我们根据已经得到的数据来构建我们的决策树。于是我们把决策树分成了两层，第一层基于属性“天气”，第二行基于“湿度”和“风”。

下图展示了一个学习过的决策树。

![Weather 1 (Decision Tree Algorithm)](img/52ddda1b43625677df6d7f50babee1f6.png)



如果特征是连续的，我们还可以设置一些阈值。

![Weather 2 (Decision Tree Algorithm)](img/583405ff111d842486cf8ed6e2206a9c.png)



### 决策树算法中熵是什么？

简而言之，熵是衡量数据混乱程度的标准。虽然你可能在数学或物理课上听过这个术语，但在这里也是一样的。在决策树中使用熵的原因是因为决策树的最终目标是将相似的数据分组到相似的类中，即整理数据。

让我们看看下面的图像，其中有初始数据集，我们需要应用决策树算法，以便将相似的数据点分组到一个类别中。

在决定分裂后，我们可以清楚地看到，大多数红圈属于一个类别，而大多数蓝叉属于另一个类别。因此，决定对基于各种因素的属性进行分类。

![Decision Split (Decision Tree Algorithm)](img/836d99942eb6fa7741e3a115c87bf9c4.png)



现在，让我们试着在这里做一些数学计算:

假设我们有“N”组项目，这些项目分为两类，现在为了根据标签对数据进行分组，我们引入比率:

![Decision Tree Algorithm 1](img/ddb5db1c1993d1ce61c490b78d5c7fc8.png)



我们集合的熵由下面的等式给出:

![Decision Tree Algorithm 2](img/e01ca7ec3d69550f58ff5cce745900e4.png)



让我们检查给定方程的图形:

![Entropy](img/90550679b4b4d1640c57d4423fb86619.png)



上图(p=0.5，q=0.5)

### 优点和缺点

下面给出了提到的优点和缺点:

#### 优势:

*   决策树很容易理解，一旦理解了，我们就可以构建它。
*   我们可以在数字和分类数据上实现决策树。
*   决策树被证明是一个健壮的模型，具有很好的结果。
*   对于大数据，它们也很省时。
*   它需要较少的努力来训练数据。

#### 缺点:

*   **不稳定性:**只有信息精确、准确，决策树才会给出有希望的结果。即使输入数据有微小的变化，也会导致树发生很大的变化。
*   **复杂度:**如果数据集很大，有很多列和行，那么设计一个有很多分支的决策树是一个非常复杂的任务。
*   **成本:**有时，成本也仍然是一个主要因素，因为当需要构建一个复杂的决策树时，它需要定量和统计分析方面的高级知识。

### 结论

在本文中，我们了解了决策树算法以及如何构建决策树。我们还看到了熵在决策树算法中扮演的重要角色，最后，我们看到了决策树的优点和缺点。

### 推荐文章

这是一个决策树算法的指南。这里我们讨论了熵的作用、工作原理、优点和缺点。您也可以浏览我们推荐的其他文章，了解更多信息——

1.  [重要的数据挖掘方法](https://www.educba.com/data-mining-methods/)
2.  [数据结构中的二分搜索法](https://www.educba.com/binary-search-in-data-structure/)
3.  [什么是数据科学？](https://www.educba.com/what-is-data-science/)
4.  [数据分析师面试问题](https://www.educba.com/data-analyst-interview-questions/)





