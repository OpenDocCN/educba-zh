# Spark 节俭服务器

> 原文:[https://www.educba.com/spark-thrift-server/](https://www.educba.com/spark-thrift-server/)

![Spark Thrift Server](../Images/122095d79b86b09ef7b9036cc935b314.png)

<noscript><img class="alignnone size-full wp-image-374453" src="../Images/122095d79b86b09ef7b9036cc935b314.png" alt="Spark Thrift Server" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-Thrift-Server.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-Thrift-Server-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-Thrift-Server-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-Thrift-Server.jpg"/></noscript>

## Spark Thrift 服务器简介

Spark SQL Thrift server 是 Apache Hive 的 HiverServer2 的一个端口，它允许 JDBC 或 ODBC 的客户机在 Spark 上通过它们各自的协议执行 SQL 查询。这是一个独立的应用程序，通过启动 start-thrift server.sh 并通过 shell 的 stop-thrift server.sh 脚本来结束它。此外，它还扩展了 spark-submit 的命令行。让我们看看如何使用 Spark 作为基于云的 SQL 引擎，并通过 Spark Thrift Server 的帮助将大数据作为 ODBC 或 JDBC 数据源公开。

### SQL 中的 Spark Thrift Server 如何工作

我们可以使用 Spark 作为基于云的 SQL 引擎，也可以通过 Spark Thrift Server 的帮助，将大数据作为 ODBC 或 JDBC 数据源公开。由于可扩展性问题和 Hadoop 的一些 SQL 框架，如 Cloudier Impala、Presto、Hive 等，SQL 等传统数据库关系引擎的发展一直在发生。像这样的框架基本上都是基于云的解决方案，每个都有自己的局限性。这些限制将在下面的文章中进一步列出。使用分布式 SQL 搜索引擎 spark，我们可以以两种形式公开数据。其中包括永久表和内存表。让我们深入研究一下。

<small>Hadoop、数据科学、统计学&其他</small>

#### 内存表

在这种类型的数据公开中，in hive 在内存中的数据存储是列格式的，这是 hive 上下文，其范围是集群。这使得访问速度更快，因此延迟降低，Spark 的使用是为了内存缓存。

#### 物理的永久记忆

使用拼花格式，数据存储在 S3。将来自多个来源的数据放入 Spark 并作为表格公开是上面提到的两种方法之一。通过这两种方式中的任何一种，都可以在 Spark thrift 服务器的帮助下将这些表作为数据源——ODBC 或 ODBC 进行访问。有多个客户。其中一些是 CLI、Beeline、ODBC、JDBC，还有一些商业智能工具，如 tableau。并且可以通过将这些可用性连接到廉价的服务器来实现数据的可视化。

下图是上面提到的插图。

**Spark 节俭服务器**

![Spark thrift server CHART](../Images/a8fb12295e0160b8cf720300f3f5de8e.png)

<noscript><img class="alignnone wp-image-374469" src="../Images/a8fb12295e0160b8cf720300f3f5de8e.png" alt="Spark thrift server CHART" width="400" height="301" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-thrift-server-CHART.png 577w, https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-thrift-server-CHART-300x226.png 300w" sizes="(max-width: 400px) 100vw, 400px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-thrift-server-CHART.png"/></noscript>

### 你知道 HiveServer2 节俭吗？

Spark thrift server 高度熟悉 Hive server2 thrift。然而，也有不同之处，如 hive job 的 MapReduce 和 was，因为 Spark Thrift server 使用 SQL spark 引擎进行搜索，这是 Spark 的主要有用功能。

下面提到的是 SQL–on–Hadoop 中的不同框架以及它们的缺点。

| 1.英帕拉 | 不支持 YARN，数据输入必须采用 parquet 格式才能充分利用其优势。 |
| 2.大 SQL | 这是 IBM 的产品，因此仅用于 IBM 客户。 |
| 3.储备 | 执行 MapReduce 来执行查询，因此可能会非常慢。 |
| 4.阿帕奇演习 | 这是一个 SQL 引擎的交互式查询，它是开源的，类似于 impala。稳定发布几年前就已经做了。这有更多的机会不能成为行业标准。 |
| 5.很快 | 最初的蜂巢创造者建造了这个框架，也就是脸书。这与黑斑羚的方法类似。输入必须以文件格式给出。必须首先调试和部署，以便稍后将其用于生产。 |

### 实现 Spark 节俭服务器的示例

下面是提到的例子:

输入是 HDFS 文件的源，并作为表记录注册到引擎 Spark SQL 中。输入可以有多个来源。例如——很少有源代码包括 XML、JSON、CSV 和其他像现实中这样复杂的内容。然后，为了注册最终数据，我们需要执行各种聚合和计算，然后使用火花表完成最终数据注册。

**代码:**

`//Here, a Spark session is created
val sparksess = SparkSession.builder()
.appName(“SQL spark”)
.config("hive.server2.thrift.port", “10000")
.config("spark.sql.hive.thriftServer.singleSession", true)
.enableHiveSupport()
.getOrCreate()
import spark.implicits._
val records = sparksess.read.format(“username").load("here/input.username")
records.createOrReplaceTempView(“records")
spark1.sql("table drop records")
ivNews.write.saveAsTable("records")`

代码的执行有两种方式。

第一个是使用火花壳的 bu:

给出 Spark shell 命令会给出一个交互 shell，当你可以运行 Spark 的所有命令时。下面给出的是 spark-shell 命令:

`spark-shell --conf spark.sql.hive.thriftServer.singleSession=true`

通过复制和粘贴上述代码将使您注册您的数据

**第二个是通过使用 Spark 提交:**

执行上述命令行的捆绑，并创建一个文件——jar。然后，安装 mvn clean 并构建 jar 文件。

下载存储库后，粘贴以下代码并运行它。

`//This can be local or nonlocal, It depends on where you run it.
spark-submit MainClass --master<master> <master_file_name_of_jar>`

用 spark 注册数据的另一种方法。

现在你必须让全世界都能看到你的数据。为此，Spark 通过 spark thrift server 自动显示注册为 ODBC/JDBC 的表，然后访问数据。

**输出:**

![Spark Thrift Server1](../Images/19cec4dcea86f9cd5d43a30bb2f98069.png)

<noscript><img class="alignnone wp-image-374263 size-full" src="../Images/19cec4dcea86f9cd5d43a30bb2f98069.png" alt="Spark Thrift Server1" width="221" height="233" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/05/Spark-Thrift-Server1.jpg"/></noscript>

### 结论

我们已经看到了 Spark Thrift SQL，它是从服务器 2 上的 Apache Hive 开发的，在操作上也与 Hiveserver2 thrift server 类似。这是由节俭集群支撑的。稍后可以与 Beeline 命令等工具一起使用。

### 推荐文章

这是一个指南火花节俭服务器。这里我们讨论 Spark Thrift 服务器的介绍，它是如何工作的，以及编程示例。您也可以浏览我们的其他相关文章，了解更多信息——

1.  [火花工具](https://www.educba.com/spark-tools/)
2.  [火花功能](https://www.educba.com/spark-functions/)
3.  [火花元件](https://www.educba.com/spark-components/)
4.  [火花版本](https://www.educba.com/spark-versions/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>