# Sqoop 面试问题

> 原文：<https://www.educba.com/sqoop-interview-questions/>

![Sqoop Interview Questions](img/b4cd6899024aad3e81bf91463b1e4cdd.png)



## Sqoop 面试问答介绍

Sqoop 是一个开源的数据传输工具；sqoop 工具在 Hadoop 生态系统和关系数据库服务器(RDBMS)之间传输数据。它从 Oracle、MySQL 等关系数据库中导入 Hadoop 文件系统( [HDFS](https://www.educba.com/hdfs-vs-hbase/) )数据。，还可以将数据从 Hadoop 文件系统导出到 RDMS。

所以你终于在 Sqoop 中找到了你的梦想工作，但想知道如何破解 Sqoop 面试，以及 2022 年 Sqoop 面试可能会有哪些问题。每次面试都不一样，工作范围也不一样。牢记这一点，我们设计了最常见的 Sqoop 面试问题和答案，以帮助您在面试中取得成功。

<small>网页开发、编程语言、软件测试&其他</small>

以下是 15 个重要的 2022 Sqoop 面试问题和答案。这些问题分为以下两部分:

### 第 1 部分 Sqoop 面试问题(基础)

第一部分包括基本的 Sqoop 面试问题和答案。

#### 1.定义 Sqoop，我们为什么要用 Sqoop？

**答案:**
Sqoop 是一款开源的数据传输工具，旨在 Hadoop 生态系统和关系数据库服务器(RDBMS)之间传输数据。Sqoop 用于从 Oracle、MySQL 等关系数据库导入数据。，到 Hadoop 文件系统( [HDFS](https://www.educba.com/hdfs-vs-hbase/) )，并用于将数据从 Hadoop 文件系统导出到关系数据库。

#### 2.Sqoop 有哪些不同的特性？

**回答:**
以下是 Sqoop 支持的不同特性

*   载荷能力
*   满载和增量装载
*   数据压缩技术
*   导入 SQL 查询结果
*   所有主要数据库的数据连接器
*   支持将数据直接加载到 Hadoop 文件系统中
*   像 Kerberos 这样的安全配置
*   并行导入或导出功能

让我们进入下一个 Sqoop 面试问题。

#### 3.说出 Sqoop 中支持的关系数据库和 Hadoop 生态系统源？

**答案:**
Sqoop 目前支持 MySQL、PostgreSQL、Oracle、MSSQL、Teradata 和 IBM 的 Netezza 作为关系数据库的一部分。
目前支持的 Hadoop 生态系统目标服务有 HDFC、Hive、HBase、H Catalog 和 Accumulo。
Sqoop 使用 MySQL 作为默认数据库。

#### 4.Sqoop 是如何工作的？

**回答:**
以上是面试中常见的 Sqoop 面试问题。为了执行数据传输，Sqoop 使用[导出和导入](https://www.educba.com/import-export-management/)命令。Map Reduce 程序将在 Sqoop 内部使用，用于将数据集存储到 HDFS。命令将与地图任务相关联，以从关系数据库中检索数据；Reduce 任务将负责将检索到的数据放入目的地(HDFS/HBase/Hive)

Sqoop 还使用各种 API 连接器来连接多个数据库。Sqoop 还提供了创建定制连接器以满足特定需求的能力。

让我们看看下面用于导入和导出的示例命令。

连接到 MySQL 数据库的命令，用于从“日志”表中导入数据

`sqoop import --connect jdbc:mysql://localhost/<databasename> --username <USER_NAME> --password <PASSWORD> --table <tablename> --m 1
sqoop import --connect jdbc:mysql://localhost/mytestdb --username root --password admin123 --table log --m 1`

将数据从 HDFS 导出到关系数据库的命令

`sqoop export --connect jdbc:mysql://localhost/sqoop_export –table <table_name> export-dir /sqoop/emp_last/part-m-00000 --update-key id
sqoop export --connect jdbc:mysql://localhost/sqoop_export --table log_table--export-dir /sqoop/data/foler1/part-m-00000`

#### 5.什么是 Sqoop Metastore？解释一下？

**答:**
Sqoop Metastore 是 Sqoop 中的一个可用工具，它将用于配置 sq OOP 应用程序，以支持以元数据形式托管共享存储库。该 Metastore 可用于执行作业，并根据用户角色和活动管理多个用户。所有多个用户可以同时执行多个任务或操作，以高效地完成任务。默认情况下，Sqoop Metastore 将作为内存中的表示来实现。当在 Sqoop 中创建作业时，作业定义存储在 Metastore 中，如果需要，将使用 Sqoop 作业列出。

#### 6.导入数据时，Sqoop 支持哪些文件格式？

**答案:**
Sqoop 使用两种文件格式进行数据导入。它们是:-分隔测试文件格式和序列文件格式。

*   **分隔文本文件格式**:分隔文本格式是导入的默认文件格式。我们仍然可以使用–as-textile 参数显式指定。同样，传递参数将设置行和列之间的分隔符。
*   **序列文件格式**:这种文件格式我们可以说是二进制文件格式。这种类型的格式文件记录存储在自定义记录特定的数据类型中，这些数据类型暴露给 [Java 类](https://www.educba.com/serialization-in-java/)。

让我们进入下一个 Sqoop 面试问题。

#### 7.我们能控制 sqoop 中映射器的数量吗？如果是，如何实现？

**回答:**
是的，我们可以通过在 Sqoop 命令中指定[参数](https://www.educba.com/how-to-evaluate-an-employers/)-num-mappers "来控制 sqoop 中的 mappers 数量。此参数可以控制地图任务的数量；也就是说，sqoop 只使用并行度。数量将根据要求决定。

*   语法:使用这些标志来控制映射器的数量:m，-num- mappers

### 第 2 部分 Sqoop 面试问题(高级)

现在让我们来看看高级 Sqoop 面试问题。

#### 8.什么是 Sqoop-merge 并解释它的用法？

**答案:**
Sqoop merge 是一个工具，它通过用新文件覆盖一个数据集的旧版本中的条目，使之成为最新版本的数据集，从而将两个维护唯一版本的不同数据集合并在一起。在合并两个不同的数据集时，有一个展平过程，它保留了数据而没有任何损失，并且高效和安全。为了执行此操作，将像“–merge-key”一样使用 merge 键盘命令

#### 9.Sqoop、flume 和 distcp 有什么区别？

**答案:**
Distcp 和 Sqoop 都是用来传输数据的。Sqoop 用于将任何类型的数据从一个 Hadoop 集群传输到另一个集群。相比之下，Sqoop 在关系数据库和 Hadoop 生态系统之间传输数据，如 [Hive](https://www.educba.com/hive-vs-hue/) 、HDFS 和 [HBase](https://www.educba.com/hbase-vs-cassandra/) 等。但是这两种方法使用相同的方法来复制数据，即拉/传输。

Flume 发布了一个工具，遵循基于代理的架构，用于将日志流式传输到 Hadoop 生态系统中。同时，Sqoop 是一个基于连接器的架构。

Flume 收集和聚合了大量的日志数据。Flume 可以从不同类型的资源中收集数据；它不考虑模式或结构化/非结构化数据。Flume 可以提取任何类型的数据。而 Sqoop 只能导入关系数据库数据，所以模式是 sqoop 必须处理的。通常，对于移动大量工作负载，flume 是最佳选择。

让我们进入下一个 Sqoop 面试问题。

#### 10.Apache Sqoop 支持哪些数据源？

**答:**
Apache sq OOP 支持的各种应用程序的不同数据源如下:

*   储备
*   HBase
*   Hadoop 分布式文件系统(HDFS)
*   HCatalog
*   积累

#### 11.Sqoop 中最常用的命令/函数是什么？

**答案:**

这是面试中问的高级 Sqoop 面试问题。Sqoop 中使用的基本命令列表如下:

*   **Codegen** -Codegen 用于生成与数据库记录通信的代码。
*   **Eval** -Sqoop Eval 帮助针对数据库运行[示例 SQL 查询](https://www.educba.com/is-sql-microsoft/)，并在控制台上提供结果。
*   **帮助**-帮助列出可用的命令
*   **Import** -Import 将表导入到 Hadoop 生态系统中。
*   **导出**-导出用于将 HDFS 数据导出到关系数据库。
*   **Create-hive-table**-该命令对于将表定义导入 Hive 非常有用
*   **Import-all-tables**-Import-all-tables 将表导入到 HDFS，形成关系数据库。
*   **List-databases**-它将列出服务器上所有的数据库。
*   它将列出一个数据库中所有的表格。
*   **版本**-显示版本信息。
*   **功能**-并行导入/导出、满载、增量加载、满载、比较、RDBMS 数据库的连接器、Kerberos 安全集成、将数据直接加载到 HDFS (Hive/HBase)

#### 12.解释使用 Sqoop 从 MySQL 或任何其他数据库导入表的最佳实践？

**答:**
从 MySQL 导入[表时，我们要确定一些事情，比如对目标服务器和数据库的认证和授权。我们需要确保我们已经在数据库上授予了必要的特权，这些特权将被访问，并且当我们连接到源和目标主机名时，还需要确保主机名解析。如果我们没有必要的权限，我们将在连接到数据库时得到一个连接失败异常。](https://www.educba.com/cheat-sheet-mysql/)

#### 13.如何更新已经导出的数据或行？

**答:**
要更新已经导出到目的地的行，我们可以使用参数“–update-key”。在这种情况下，使用逗号分隔的列列表，该列表唯一地标识一行，并且所有这些列都在生成的更新查询的 WHERE 子句中使用。查询的 SET 部分将处理所有其他表列。

让我们进入下一个 Sqoop 面试问题。

#### 14.如何在 Apache Sqoop 中配置安装 JDBC 驱动？

**答案:**
Apache Sqoop 中的 JDB 驱动可以基于 Cloudera 或 Hortonworks 等 Hadoop 提供者进行配置。根据 Hadoop 提供者的不同，它的配置略有不同。Cloudera 中的 JDBC 可以通过创建一个像 */var/lib/这样的库文件夹来配置。*对于任何需要根据需求进行配置的第三方库，都可以这样做。这样，任何类型的数据库都可以使用其 JDBC 驱动程序进行配置。除了 JDBC 驱动程序，Apache Sqoop 还需要一个连接器来建立不同关系数据库之间的连接。与数据库建立连接所需的主要组件是通过数据库提供者的驱动程序和连接器。

#### 15.什么是 split-by 子句，我们何时使用它？

**答案:**
split-by 参数用于将要导入的数据切片到多个并行任务中。使用这个参数，我们可以指定列名；这些是列名，sqoop 将根据这些列名把要导入的数据分成多个块，它们将以并行方式运行。这是在 Sqoop 中调优性能的技术之一。

### 推荐文章

这是一个 Sqoop 面试问题的指南。这里我们列出了面试中经常被问到的十大面试问题和答案。您也可以阅读以下文章，了解更多信息——

1.  [数据库测试面试问题](https://www.educba.com/database-testing-interview-questions/)
2.  [h 基本面试问题](https://www.educba.com/hbase-interview-questions/)
3.  [有经验的 PHP 面试问题](https://www.educba.com/php-interview-questions/)
4.  [Scrum 大师面试问题](https://www.educba.com/scrum-master-interview-questions/)





