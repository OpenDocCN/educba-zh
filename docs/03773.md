# 机器学习中的回归

> 原文:[https://www.educba.com/regression-in-machine-learning/](https://www.educba.com/regression-in-machine-learning/)

![regression of machine learning](../Images/d13e3d2448e75134e9417aee92e4aac0.png)

<noscript><img class="alignnone size-full wp-image-282725" src="../Images/d13e3d2448e75134e9417aee92e4aac0.png" alt="regression of machine learning" width="863" height="482" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/01/regression-of-machine-learning.jpg.webp 863w,https://cdn.educba.com/academy/wp-content/uploads/2020/01/regression-of-machine-learning-300x168.jpg.webp 300w,https://cdn.educba.com/academy/wp-content/uploads/2020/01/regression-of-machine-learning-768x429.jpg.webp 768w" sizes="(max-width: 863px) 100vw, 863px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/01/regression-of-machine-learning.jpg.webp"/></noscript>

## 机器学习中的回归介绍

以下文章提供了机器学习中回归的概述。回归意味着使用输入数据预测值。回归模型用于预测连续值。它主要用于寻找变量和预测之间的关系。回归模型根据因变量和自变量之间的关系而有所不同。

### 机器学习中的回归类型

回归有不同的类型:

<small>Hadoop、数据科学、统计学&其他</small>

*   **简单线性回归:**简单线性回归是以自变量为基础的目标变量。线性回归是一种基于监督学习的机器学习算法，它执行回归任务。
*   **多项式回归:**多项式回归将原始特征转化为给定次数或变量的多项式特征，然后对其应用线性回归。
*   **支持向量回归:** [支持向量回归](https://www.educba.com/support-vector-regression/)识别具有最大边缘的超平面，使得最大数量的数据点在边缘内。
*   **决策树回归:**决策树是通过将数据划分为包含具有相似值的实例的子集而构建的树。它还可以用于回归和分类。
*   **随机森林回归:**随机森林是一种集成方法，其中我们考虑了几个决策回归树的预测。

### 机器学习中的回归模型

回归模型用于创建数学方程，该方程将 y 定义为 x 变量的操作。这个方程可能习惯于根据预测变量 x 的最新值来预测最终结果“y”

统计回归方程可以写成:

y = B0 + B1*x

在哪里，

*   B0 是截距。
*   B1 是回归权重或与变量 x 相关的常数

确定这些统计回归系数以减少误差，同时预测最终结果值。这种计算β系数的方法被称为正态最小二乘法。如果最终结果和变量不是线性的，我们将创建一个非线性回归，如多项式回归。

当我们在回归模型中有多个值，并希望挑选出最简单的变量组合时，我们将创建最佳预测模型，称为模型选择。模型选择比较多个模型，选择预测误差最小的最简单模型。

在某些情况下，我们得到了包含相关信息的可变信息集。在这种情况下，第一信息可以被总结成几个变量，这些变量是第一变量的线性组合。这个新变量可以用来建立一个线性模型，这个模型可以是信息的多个函数。这种方法被称为基于主元素的策略，它是主成分回归的组合。在这种情况下，它惩罚了有几个变量的模型。惩罚回归包括岭回归和套索回归。

用于检查模型的指标有

*   **均方根误差:**测量模型预测误差，该误差对应于最终结果的已知发现值与模型预期值之间的典型差异。
*   **调整后的 R-Square:** 表示模型解释的信息内的变异比例。这符合模型的标准。上层是 R2，上层是模型。

从身高(x)用体重(y)来说吧。

那么我们的统计回归模型说明的公式将是:

y = B0 + B1 * x1

或者

Weight = B0 + B1* height

根据上面的等式:

*   B0 是偏置常数。
*   B1 是高度列的系数。

一旦得到系数值，我们就可以用不同的高度值来预测体重。

**举例:**

假设 b0 = 0.3，b1 = 0.5

让我们把他们带进去，计算一下一个峰值为 192 厘米的人的负荷。

*   重量= 0.3 + 0.5* 192
*   重量= 96.3

根据上面的等式，它可以被绘制成二维的线，其中 B0 将是起点，而不管给定的高度值。我们可以预测不同的高度值，以获得创建线条的重量值。

### 线性回归在机器学习中的实现

线性回归有多种应用方式，其中一些列举如下:

*   销售预测
*   风险分析
*   住房申请
*   金融应用

用于实施统计回归的过程，并以多种方式利用该过程，其中一些方式如下所述:

*   加载数据
*   探索数据
*   分割数据
*   训练和分割数据
*   生成模型
*   撤离的准确性

### 线性回归的优点和缺点

线性回归有几个优点和缺点:

#### 优势:

*   当数据集是线性可分的时，线性回归表现良好。我们可以用它来发现变量之间关系的本质。
*   它更容易实现、解释，并且训练起来非常高效。
*   它易于过度拟合，但可以通过使用一些降维技术、正则化技术和交叉验证来轻松避免。
*   它有超出特定数据集的外推。

#### 缺点:

*   **线性假设:**它假设输入和输出之间的关系是线性的。
*   **去除噪声:**假设输入和输出变量没有噪声。
*   **去除共线性:**当我们有高度相关的输入变量时，它会过度拟合数据。
*   **高斯分布:**如果输入和输出变量具有高斯分布，将会创建许多可靠的预测。
*   如果我们倾向于使用调整输入变量、开发标准化或社会控制，通常会产生许多可靠的预测。
*   **易受离群值影响:**对离群值非常敏感。因此，在对数据集应用线性回归之前，需要移除离群值。

### 结论

线性回归是一种习惯于分析变量之间关系的工具，但它在实际中并不适用。在这篇文章中，我们已经看到，关于回归及其类型什么是回归模型，它是如何选择的？线性回归的例子。实施统计回归的线性回归步骤的使用以及线性回归的优点和缺点。

### 推荐文章

这是机器学习中的回归指南。在这里，我们讨论的介绍，回归的类型，实施，优点和缺点。您也可以浏览我们的其他相关文章，了解更多信息——

1.  [R 中的简单线性回归](https://www.educba.com/simple-linear-regression-in-r/)
2.  [OLS 回归于 R](https://www.educba.com/ols-regression-in-r/)
3.  [泊松回归中的 R](https://www.educba.com/poisson-regression-in-r/)
4.  [机器学习技术](https://www.educba.com/machine-learning-techniques/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>