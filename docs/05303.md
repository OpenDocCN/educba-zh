# 火花簇

> 原文:[https://www.educba.com/spark-cluster/](https://www.educba.com/spark-cluster/)

![Spark Cluster](../Images/36232a3e1ebb52bb8e1790060b12f593.png)

<noscript><img class="alignnone size-full wp-image-385096" src="../Images/36232a3e1ebb52bb8e1790060b12f593.png" alt="Spark Cluster" width="900" height="500" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/09/Spark-Cluster.jpg 900w, https://cdn.educba.com/academy/wp-content/uploads/2020/09/Spark-Cluster-300x167.jpg 300w, https://cdn.educba.com/academy/wp-content/uploads/2020/09/Spark-Cluster-768x427.jpg 768w" sizes="(max-width: 900px) 100vw, 900px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/09/Spark-Cluster.jpg"/></noscript>

## 火花簇简介

安装 Spark 的平台称为集群。分布式模型上的 Spark 可以在集群的帮助下运行。一个集群中有 x 个 workers 和一个 master。形成集群划分并在主机中调度资源的那个。跨应用程序分配资源是集群管理器的主要工作。通过作为集群上的外部服务来获取资源。集群管理器的工作被分派。Spark 支持可插拔集群管理器。集群管理器在 Spark 中处理 executor 进程。

**语法**

<small>Hadoop、数据科学、统计学&其他</small>

Apache Spark 集群的语法:

对于 K-means 数据聚类算法，这是实现 API。

`org.apache.spark.mllib.clustering`

### Apache Spark 集群是如何工作的？

集群管理器分为三种类型，它们支持 Apache Spark 系统。它们列举如下:

*   集群的独立管理器
*   Hadoop 中的纱线
*   阿帕奇的梅索斯

让我们一个接一个地讨论每种类型。

#### 1.Apache Spark 系统中的独立集群管理器

这种模式在 Spark 中，只是包含了一个集群管理器。这可以在 Linux、Mac、Windows 上运行，因为它使得在 Spark 上建立集群变得很容易。在集群环境中，这通常是运行任何 Spark 应用程序的简单方法。

#### 2\. Apache Mesos

通过动态的资源共享和隔离，Mesos 处理分布式环境中的工作负载。在大规模集群环境中，这有助于部署和管理。Apache Mesos 可以将集群中现有的机器和节点资源集中在一起。由于这是一个节点抽象，对于不同的工作负载，这减少了分配特定机器的开销。对于 Hadoop 和 bigdata 集群，它是一个资源管理平台。Apache Meso 由 Twitter 和 Airbnb 等公司使用，在 Mac 和 Linux 上运行。虚拟化的反面是 Apache Mesos。虚拟化中的一个物理资源分成许多虚拟资源。Mesos 中的许多物理资源都集中在一个虚拟资源中。

#### 3.纱线 Hadoop

2012 年，YARN 成为 Hadoop 的子项目。它也被称为 MapReduce 2.0。在不同的守护进程中，线程将任务调度和资源管理的功能分成两部分。预申请申请硕士和全球资源经理(AM 和 GRM)是要达到的目标。一个应用或者是一个单独的作业，或者是一个图的 DAG。

#### 4.库伯内特斯

对于自动化部署，它是一个开源系统，用于扩展和管理容器化的应用程序。

![Kubernetes](../Images/7e8c1cd07bb51ed3e9408adb0d5612e2.png)

<noscript><img class="alignnone wp-image-385097" src="../Images/7e8c1cd07bb51ed3e9408adb0d5612e2.png" alt="Kubernetes" width="536" height="289" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/09/Kubernetes.png 662w, https://cdn.educba.com/academy/wp-content/uploads/2020/09/Kubernetes-300x162.png 300w" sizes="(max-width: 536px) 100vw, 536px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/09/Kubernetes.png"/></noscript>

与主程序(称为驱动程序)中的 SparkContext 对象相协调，在集群上，Spark 应用程序作为独立的进程集运行。上述集群管理器类型专门用于在集群上运行。它们在所有应用程序之间分配资源。应用程序在连接后被发送到代码，并且集群中的节点上的执行器被获取，这些执行器是运行计算并且同时还为用户应用程序存储数据的进程。在发送到代码之后，它们被发送到执行器，执行器由 Python 和 Jar 文件定义，并被传递到 Spark 上下文。最后，所有的任务都被发送到执行器，由 SparkContext 运行。

**代码:**

`public abstract class ClusteringColonCancerData {
protected void obtainClusters(){
// Set application name
String appName = "ClusteringExample";
// Initialize Spark configuration & context
SparkConf sparkConf = new SparkConf().setAppName(appName)
.setMaster("local[1]").set("spark.executor.memory", "1g");
JavaSparkContext sc = new JavaSparkContext(sparkConf);
// Read data file from Hadoop file system.
String path = "hdfs://localhost:9000/user/konur/COLRECT.txt";
// Read the data file and return it as RDD of strings
JavaRDD<String> tempData = sc.textFile(path);
JavaRDD<Vector> data = tempData.map(mapFunction);
data.cache();
Enumeration<Integer> keysPoints = clusteredPoints.keys();
while (keysPoints.hasMoreElements()) {
Integer i = keysPoints.nextElement();
System.out.println("\nCluster " + i + " points:");
Hashtable<java.util.Vector<Integer>, Integer> dataPoints =
clusteredPoints
.get(i);
Enumeration<java.util.Vector<Integer>> keyVectors = dataPoints
.keys();
while (keyVectors.hasMoreElements()) {
java.util.Vector<Integer> pnt = keyVectors.nextElement();
System.out.println("[ 'stage group': " + pnt.get(0)
+ ", 'regional nodes positive': " + pnt.get(1) + "]"
+ "  repeated " + dataPoints.get(pnt) + " time(s). ]");
}
}`

**输出:**

![Spark Cluster1](../Images/e545869145791d69e0bbce78baa3ced2.png)

<noscript><img class="alignnone wp-image-383513 size-full" src="../Images/e545869145791d69e0bbce78baa3ced2.png" alt="Spark Cluster1" width="606" height="97" srcset="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Cluster1.jpg 606w, https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Cluster1-300x48.jpg 300w" sizes="(max-width: 606px) 100vw, 606px" data-original-src="https://cdn.educba.com/academy/wp-content/uploads/2020/06/Spark-Cluster1.jpg"/></noscript>

### 结论

总而言之，Spark 有助于简化处理大量实时或归档数据(包括结构化和非结构化数据)的挑战性和计算密集型任务，无缝集成相关的复杂功能，如机器学习和图形算法。Spark 为大众带来大数据处理。

### 推荐文章

这是一个星火集群的指南。在这里，我们将详细讨论 Spark 集群的介绍、语法以及它如何与不同类型一起工作。您也可以浏览我们的其他相关文章，了解更多信息——

1.  [火花版本](https://www.educba.com/spark-versions/)
2.  [火花广播](https://www.educba.com/spark-broadcast/)
3.  [火花工具](https://www.educba.com/spark-tools/)
4.  [火花元件](https://www.educba.com/spark-components/)

<footer class="entry-footer">

<aside class="sidebar sidebar-primary widget-area" role="complementary" aria-label="Primary Sidebar">Primary Sidebar</aside>

</footer>