# 什么是蜂巢？

> 原文：<https://www.educba.com/what-is-a-hive/>

![What is a Hive?](img/ea5800e2986177330c52204c914517b5.png)



## 什么是蜂巢？

Hadoop 平台中用于汇总、分析和查询较大数据量的数据仓库系统称为 Hive。SQL 查询被转换成 MapReduce 等其他形式，从而更大程度地减少了作业。这是一种提取-转换-加载过程，用于分析和处理结构化和非结构化数据。它使用其他查询语言执行 DDL 和 DML 操作，例如为查询和处理数据而提供的 HQL。Hive 构建于 Hadoop 之上，用于处理数据。它将输入翻译成 SQL 语言来编译和产生数据结果。

### 了解配置单元

以下是蜂巢的主要组成部分:

<small>Hadoop、数据科学、统计学&其他</small>

#### 1\. Meta Store

存储元数据的存储库称为配置单元元存储。元数据由关于表的不同数据组成，比如它们的位置、模式、关于分区的信息，这有助于监视集群中各种分布的数据进度。它还跟踪数据并复制数据，这在数据丢失等紧急情况下提供了备份。元数据信息存在于关系数据库中，而不在 Hadoop 文件系统中。

#### 2.驾驶员

在执行配置单元查询语言语句时，驱动程序接收该语句，并在整个执行周期中控制该语句。随着语句的执行，驱动程序还存储从执行中生成的元数据。它还创建会话来监控不同执行的进度和生命周期。MapReduce 作业完成 reducing [操作后，驱动程序收集查询的所有数据和结果。](https://www.educba.com/what-is-mapreduce/)

#### 3.编译程序

它用于将配置单元查询语言翻译成 MapReduce 输入。它调用一个方法来执行 MapReduce 读取 HiveQL 输出所需的步骤和任务。

#### 4.【计算机】优化程序

优化器的主要任务是提高效率和可伸缩性，在简化操作之前转换数据的同时创建任务。它还执行转换，如聚合、单个连接到多个连接的管道转换。

#### 5.执行者

在编译和优化步骤之后，执行器的主要任务是执行任务。执行器的主要任务是与 Hadoop 作业跟踪器进行交互，以调度准备运行的任务。

#### 6.UI、节俭服务器和 CLI

其他客户端使用节俭服务器与配置单元引擎进行交互。用户界面和命令行界面有助于提交查询以及进程监控和指令，以便外部用户可以与配置单元进行交互。

下面是展示 hive 与 Hadoop 框架交互[的步骤](https://www.educba.com/hadoop-framework/)

#### 7.执行查询

查询从配置单元界面(如命令行或 web UI)发送到驱动程序。驱动程序可以是任何数据库驱动程序，如 JDB 或 ODBC 等。

#### 8.获取计划

可以在查询编译器的帮助下检查查询或查询计划的要求的语法，该查询编译器通过查询并由驱动程序调用。

#### 9.获取元数据

元存储可以驻留在任何数据库中，编译器请求访问元数据。

#### 10.发送元数据

在编译器的请求下，元存储发送元数据。

#### 11.发送计划

编译器在验证编译器发送的要求时将计划发送给驱动程序。这一步完成了查询的解析和编译。

#### 12.执行计划

驱动程序将执行计划发送给执行引擎。

#### 13.执行作业

执行作业是在后端运行的 MapReduce 作业。然后，它遵循 Hadoop 框架的常规惯例——执行引擎将向驻留在名称节点上的作业跟踪器发送作业，而名称节点又会将作业分配给 data note 中的任务跟踪器。MapReduce 作业在这里执行。

#### 14.元数据操作

在执行作业时，执行引擎可以用元存储执行元数据操作。

#### 15.获取结果

完成处理后，数据节点将结果传递给执行引擎。

#### 16.发送结果

驱动程序从执行引擎接收结果。

#### 17.结果发送

最后，配置单元接口接收来自驱动程序的结果。因此，通过执行上述步骤，在 Hive 中执行完整的查询。

### 蜂巢是如何让工作变得如此简单的？

*   Hive 是一个建立在 Hadoop 之上的数据仓库框架，它可以帮助用户对大量数据集执行数据分析、数据查询和数据汇总。
*   HiveQL 是一个独特的特性，它看起来像存储在数据库中的 [SQL 数据，并执行广泛的分析。](https://www.educba.com/what-is-sql/)
*   我们能够以非常高的速度读取数据并将数据写入数据仓库，并且它可以管理分布在多个位置的大型数据集。
*   除此之外，hive 还为存储在数据库中的数据提供了结构，用户能够使用命令行工具或 JDBC 驱动程序连接到 hive。

### 顶级公司

使用大数据的主要组织:

*   蜂巢般的脸书
*   亚马逊、沃尔玛
*   许多其他人

### 你能用 Hive 做什么？

*   蜂巢式的数据查询、数据汇总和数据分析有很多功能。它支持一种称为 HiveQL 或 Hive Query Language 的查询语言。
*   Hive query 语言查询被翻译成 MapReduce 作业，该作业在 Hadoop 集群上处理。
*   除此之外，Hiveql 还减少了可以添加到查询中的脚本。通过这种方式，HiveQL 增加了模式设计的灵活性，这也[支持数据反序列化](https://www.educba.com/deserialization-in-c-sharp/)和数据序列化。

### 使用 Hive

以下是 Hive 中的一些操作细节。

配置单元数据类型大致分为以下四种类型:

*   列类型
*   文字
*   空值
*   复杂类型

#### 1.列类型

这些是配置单元的列数据类型。

这些分类如下:

*   **整型:**整型数据用整型数据类型表示。符号是 INT。任何超过 INT 上限的数据都必须被赋予 BIGINT 的数据类型。同理，任何低于 INT 下限的数据都需要赋 SMALLINT。还有一种数据类型叫做 TINYINT，它甚至比 SMALLINT 还要小。
*   **字符串类型:**字符串数据类型在 hive 中用单引号(')或双引号(")表示。它可以有两种类型–VARCHAR 或 CHAR。
*   **时间戳:** Hive 时间戳支持 java.sql.Timestamp 格式“YYYY-MM-DD HH:MM:ss . ffffffff”和格式“YYYY-MM-DD HH:MM:ss . ffffffff”。
*   **日期:**日期在 hive 中以 YYYY-MM-DD 表示年-月-日的格式表示。
*   **小数:**hive 中的小数以 java big decimal 格式表示，用于表示不可变的任意精度。它以十进制(精度，小数位数)格式表示。
*   **联合类型:**联合在配置单元中用于创建异构数据类型的集合。可以使用 create union 创建它。

下面是一个例子:

**代码:**

`UNIONTYPE<int, double, array<string>, struct<a:int,b:string>>
{0:1}
{1:2.0}
{2:["three","four"]}
{3:{"a":5,"b":"five"}}
{2:["six","seven"]}
{3:{"a":8,"b":"eight"}}
{0:9}
{1:10.0}`

#### 2 .文字

配置单元中使用的文字很少。

*   **浮点型:**用带小数点的数字表示。这些非常类似于 double 数据类型。
*   **十进制类型:**这种类型的数据只包含十进制类型的数据，但浮点值的范围比双精度数据类型大。小数类型的范围大致为-10 <sup>-308</sup> 到 10 <sup>308。</sup>

#### 3.空值

特殊值 NULL 表示配置单元中缺少的值。

#### 4.复杂类型

下面是在配置单元中发现的不同复杂类型:

*   **数组:**数组在[中以与 java](https://www.educba.com/install-java-8/) 相同的形式表示在一个 hive 中。语法类似于数组<数据类型>。
*   **地图:**地图在 hive 中以与 java 相同的形式表示。

语法就像地图。

*   <primitivetype datatype="">。</primitivetype>
*   **结构**:配置单元中的结构被表示为带有注释的复杂数据。

**语法:**

`STRUCT<columnname : datatype [COMMENT columncomment], ...>.`

除此之外，我们还可以创建数据库、表格、对它们进行分区以及许多其他功能。

*   **数据库:**它们是包含表集合的名称空间。

下面是在配置单元中创建数据库的语法。

`CREATE DATABASE [IF NOT EXISTS] sampled;`

如果不再需要，也可以删除数据库。

下面是删除数据库的语法。

`DROP DATABASE [IF EXISTS] sampled;`

*   **表:**也可以在 hive 中创建表来存储数据。

下面是创建表格的语法。

`CREATE [TEMPORARY] [EXTERNAL] TABLE [IF NOT EXISTS] [db_name.] table_nam
[(col_name data_type [COMMENT col_comment], ...)] [COMMENT table_comment
[ROW FORMAT row_format] [STORED AS file_format]`

如果不再需要某个表，也可以将其删除。

下面是删除表的语法。

`DROP TABLE [IF EXISTS] table_name;`

### 优势

下面是提到的优点:

*   Apache Hive 的主要优势是用于数据查询、汇总和分析。它是为提高开发人员的生产力而设计的，但也带来了增加延迟和降低效率的代价。
*   Apache Hive 提供了广泛的用户自定义函数，这些函数可以与 RHipe、Apache Mahout 等其他 Hadoop 包互连。当处理复杂的分析处理和多种数据格式时，它在很大程度上帮助了开发人员。主要用于[数据入库](https://www.educba.com/career-in-data-warehousing/)，即用于报表和数据分析的系统。
*   它包括清理、转换和建模数据，以提供关于各种业务方面的有用信息，这将有助于为组织带来好处。数据分析有许多不同的方面和方法，包括在不同的商业模型、社会科学领域等中使用各种名称的不同技术。
*   它对用户非常友好，允许用户同时访问数据，从而增加了响应时间。与其他类型的大型数据集查询相比，hive 的响应时间要快得多。在添加更多数据和增加集群中的节点数量时，它在性能方面也更加灵活。

### 为什么要用蜂巢？

*   除了数据分析，hive 还提供了广泛的选项来将数据存储到 [HDFS](https://www.educba.com/what-is-hdfs/) 中。
*   它支持不同的文件系统，如平面文件或文本文件，由二进制键值对组成的序列文件，在列数据库中存储表的列的 RC 文件。
*   现在，最适合 Hive 的文件被称为 ORC 文件或优化的行列文件。

### 我们为什么需要蜂巢？

*   在当今世界，Hadoop 与用于大数据处理的最广泛的技术联系在一起。
*   用于数据分析和其他大数据处理的非常丰富的工具和技术集合。

### 谁是学习 Hive 技术的合适受众？

大多数具有开发人员、Hadoop 分析、系统管理员、数据仓库、SQL 专业人员和 Hadoop 管理背景的人都可以掌握 hive。

### 这项技术将如何帮助你的职业发展？

*   它是现在市场上炙手可热的技能之一，是大数据 Hadoop 世界中数据分析的最佳工具之一。
*   对大型数据集进行分析的大企业总是在寻找拥有合适技能的人，以便他们能够管理和查询海量数据。
*   这是最近几天在大数据技术市场上可用的最好的工具之一，可以帮助世界各地的组织进行数据分析。

### 结论

除了上面给出的功能，hive 还有更高级的功能。hive 以极高的准确性处理大量数据集的能力使 hive 成为大数据平台中用于分析的最佳工具之一。此外，由于定期改进和最终用户的易用性，它还有很大的潜力在未来几天成为领先的大数据分析工具之一。

### 推荐文章

这是一个什么是蜂巢的指南？在这里，我们借助例子讨论了 Hive 的主要组件、优点、技巧和工作方式。您也可以浏览我们推荐的其他文章，了解更多信息——

1.  [配置单元命令](https://www.educba.com/hive-command/)
2.  [蜂巢面试问题](https://www.educba.com/hive-interview-questions/)
3.  [jdbc 鼠标](https://www.educba.com/jdbc-hive/)
4.  [蜂巢 UDF](https://www.educba.com/hive-udf/)





